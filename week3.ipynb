{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1661,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomTreesEmbedding, ExtraTreesClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1662,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(r'C:\\Users\\rlee3104\\MH3\\MessagePolarity_ParticipantsData\\Train.csv')\n",
    "test = pd.read_csv(r'C:\\Users\\rlee3104\\MH3\\MessagePolarity_ParticipantsData\\Test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1663,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all_data size is : (1474, 53)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rlee3104\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "ntrain = train.shape[0]\n",
    "ntest = test.shape[0]\n",
    "y_train = train.IsGoodNews.values\n",
    "all_data = pd.concat((train, test)).reset_index(drop=True)\n",
    "all_data.drop(['IsGoodNews'], axis=1, inplace=True)\n",
    "print(\"all_data size is : {}\".format(all_data.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1664,
   "metadata": {},
   "outputs": [],
   "source": [
    "#14, 26, 37, 38, 36, 42, 6, 34, 27z1, 31, 24, 25, 33, 35, 41\n",
    "all_data.drop(['Freq_Of_Word_41','Freq_Of_Word_25','Freq_Of_Word_33','Freq_Of_Word_38','Freq_Of_Word_39','Freq_Of_Word_29','Freq_Of_Word_30'],inplace=True , axis=1)\n",
    "#all_data.drop(['Freq_Of_Word_14','Freq_Of_Word_26','Freq_Of_Word_37','Freq_Of_Word_38','Freq_Of_Word_36','Freq_Of_Word_42','Freq_Of_Word_6','Freq_Of_Word_34','Freq_Of_Word_27','Freq_Of_Word_21','Freq_Of_Word_31','Freq_Of_Word_24','Freq_Of_Word_25','Freq_Of_Word_33','Freq_Of_Word_35','Freq_Of_Word_41'],inplace=True,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1665,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all_data['feat_1'] = all_data['StylizedLetters'] * all_data['TotalEmojiCharacters']\n",
    "#all_data['feat_2'] = all_data['StylizedLetters'] * all_data['LengthOFFirstParagraph']\n",
    "#all_data['feat_3'] = all_data['LengthOFFirstParagraph'] * all_data['TotalEmojiCharacters']\n",
    "\n",
    "#all_data['feat_4'] = all_data['StylizedLetters'] * all_data['TotalEmojiCharacters'] * all_data['LengthOFFirstParagraph']\n",
    "#all_data['feat_5'] = np.log(all_data['LengthOFFirstParagraph'])# / all_data['StylizedLetters'] \n",
    "#all_data['feat_6'] = np.log(all_data['TotalEmojiCharacters'])\n",
    "\n",
    "#all_data['feat_7'] = np.log(all_data['StylizedLetters'])\n",
    "#_data['feat_4'] = all_data['StylizedLetters'] - all_data['TotalEmojiCharacters']\n",
    "##a#ll_data['feat_5'] = all_data['StylizedLetters'] -  all_data['LengthOFFirstParagraph']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1647,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"all_data['feat_1'] = all_data['StylizedLetters'] + all_data['TotalEmojiCharacters']\\nall_data['feat_2'] = all_data['StylizedLetters'] + all_data['LengthOFFirstParagraph']\\nall_data['feat_3'] = all_data['LengthOFFirstParagraph'] + all_data['TotalEmojiCharacters']\\nall_data['feat_4'] = all_data['StylizedLetters'] - all_data['TotalEmojiCharacters']\\nall_data['feat_5'] = all_data['StylizedLetters'] -  all_data['LengthOFFirstParagraph']\\nall_data['feat_6'] = all_data['LengthOFFirstParagraph'] - all_data['TotalEmojiCharacters']\\nall_data['feat_7'] = all_data['StylizedLetters'] * all_data['TotalEmojiCharacters']\\nall_data['feat_8'] = all_data['StylizedLetters'] * all_data['LengthOFFirstParagraph']\\nall_data['feat_9'] = all_data['LengthOFFirstParagraph'] * all_data['TotalEmojiCharacters']\\n\\n\\nall_data['feat_10'] =  all_data['TotalEmojiCharacters'] / all_data['StylizedLetters'] \\nall_data['feat_11'] =  all_data['TotalEmojiCharacters'] /all_data['LengthOFFirstParagraph'] \\nall_data['feat_12'] =  all_data['StylizedLetters'] / all_data['LengthOFFirstParagraph'] \\n\\n\\n#all_data['feat_13'] = 1/np.exp(all_data['StylizedLetters'])\\n#all_data['feat_14'] = 1/np.exp(all_data['LengthOFFirstParagraph'])\\n#all_data['feat_15'] = 1/np.exp(all_data['TotalEmojiCharacters'])\\n\\n\\nall_data['feat_16'] = 1/all_data['StylizedLetters']\\nall_data['feat_17'] = 1/all_data['LengthOFFirstParagraph']\\nall_data['feat_18'] = 1/all_data['TotalEmojiCharacters']\\n\\n\\n\\nall_data['feat_19'] = all_data['StylizedLetters'] + all_data['LengthOFFirstParagraph'] + all_data['TotalEmojiCharacters']\\nall_data['feat_20'] = all_data['StylizedLetters'] * all_data['LengthOFFirstParagraph'] * all_data['TotalEmojiCharacters']\\n\\nall_data['feat_21'] = 1/all_data['StylizedLetters'] * 1/all_data['LengthOFFirstParagraph'] * 1/all_data['TotalEmojiCharacters']\\n\\n\\n\\nall_data['feat_22'] = 1 / all_data['StylizedLetters'] + 1 / all_data['LengthOFFirstParagraph'] + 1/ all_data['TotalEmojiCharacters']\\n\\n\\n\\nall_data['feat_23'] =  all_data['StylizedLetters'] / all_data['TotalEmojiCharacters']  \\nall_data['feat_24'] =   all_data['LengthOFFirstParagraph'] / all_data['TotalEmojiCharacters'] \\nall_data['feat_25'] =  all_data['LengthOFFirstParagraph'] / all_data['StylizedLetters']  \\n\\n\""
      ]
     },
     "execution_count": 1647,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''all_data['feat_1'] = all_data['StylizedLetters'] + all_data['TotalEmojiCharacters']\n",
    "all_data['feat_2'] = all_data['StylizedLetters'] + all_data['LengthOFFirstParagraph']\n",
    "all_data['feat_3'] = all_data['LengthOFFirstParagraph'] + all_data['TotalEmojiCharacters']\n",
    "all_data['feat_4'] = all_data['StylizedLetters'] - all_data['TotalEmojiCharacters']\n",
    "all_data['feat_5'] = all_data['StylizedLetters'] -  all_data['LengthOFFirstParagraph']\n",
    "all_data['feat_6'] = all_data['LengthOFFirstParagraph'] - all_data['TotalEmojiCharacters']\n",
    "all_data['feat_7'] = all_data['StylizedLetters'] * all_data['TotalEmojiCharacters']\n",
    "all_data['feat_8'] = all_data['StylizedLetters'] * all_data['LengthOFFirstParagraph']\n",
    "all_data['feat_9'] = all_data['LengthOFFirstParagraph'] * all_data['TotalEmojiCharacters']\n",
    "\n",
    "\n",
    "all_data['feat_10'] =  all_data['TotalEmojiCharacters'] / all_data['StylizedLetters'] \n",
    "all_data['feat_11'] =  all_data['TotalEmojiCharacters'] /all_data['LengthOFFirstParagraph'] \n",
    "all_data['feat_12'] =  all_data['StylizedLetters'] / all_data['LengthOFFirstParagraph'] \n",
    "\n",
    "\n",
    "#all_data['feat_13'] = 1/np.exp(all_data['StylizedLetters'])\n",
    "#all_data['feat_14'] = 1/np.exp(all_data['LengthOFFirstParagraph'])\n",
    "#all_data['feat_15'] = 1/np.exp(all_data['TotalEmojiCharacters'])\n",
    "\n",
    "\n",
    "all_data['feat_16'] = 1/all_data['StylizedLetters']\n",
    "all_data['feat_17'] = 1/all_data['LengthOFFirstParagraph']\n",
    "all_data['feat_18'] = 1/all_data['TotalEmojiCharacters']\n",
    "\n",
    "\n",
    "\n",
    "all_data['feat_19'] = all_data['StylizedLetters'] + all_data['LengthOFFirstParagraph'] + all_data['TotalEmojiCharacters']\n",
    "all_data['feat_20'] = all_data['StylizedLetters'] * all_data['LengthOFFirstParagraph'] * all_data['TotalEmojiCharacters']\n",
    "\n",
    "all_data['feat_21'] = 1/all_data['StylizedLetters'] * 1/all_data['LengthOFFirstParagraph'] * 1/all_data['TotalEmojiCharacters']\n",
    "\n",
    "\n",
    "\n",
    "all_data['feat_22'] = 1 / all_data['StylizedLetters'] + 1 / all_data['LengthOFFirstParagraph'] + 1/ all_data['TotalEmojiCharacters']\n",
    "\n",
    "\n",
    "\n",
    "all_data['feat_23'] =  all_data['StylizedLetters'] / all_data['TotalEmojiCharacters']  \n",
    "all_data['feat_24'] =   all_data['LengthOFFirstParagraph'] / all_data['TotalEmojiCharacters'] \n",
    "all_data['feat_25'] =  all_data['LengthOFFirstParagraph'] / all_data['StylizedLetters']  \n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1666,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Skew in numerical features: \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Skew</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Freq_Of_Word_4</th>\n",
       "      <td>36.141607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TotalEmojiCharacters</th>\n",
       "      <td>24.140908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Freq_Of_Word_48</th>\n",
       "      <td>18.952649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Freq_Of_Word_44</th>\n",
       "      <td>15.875713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Freq_Of_Word_24</th>\n",
       "      <td>14.662007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Freq_Of_Word_8</th>\n",
       "      <td>13.866275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Freq_Of_Word_47</th>\n",
       "      <td>12.821998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Freq_Of_Word_10</th>\n",
       "      <td>11.965818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Freq_Of_Word_49</th>\n",
       "      <td>11.514172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Freq_Of_Word_27</th>\n",
       "      <td>10.226667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Freq_Of_Word_32</th>\n",
       "      <td>10.193402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Freq_Of_Word_34</th>\n",
       "      <td>10.165708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Freq_Of_Word_46</th>\n",
       "      <td>9.347865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Freq_Of_Word_42</th>\n",
       "      <td>9.263066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Freq_Of_Word_40</th>\n",
       "      <td>9.197374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Freq_Of_Word_31</th>\n",
       "      <td>9.005282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Freq_Of_Word_36</th>\n",
       "      <td>8.969284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Freq_Of_Word_22</th>\n",
       "      <td>8.785907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Freq_Of_Word_50</th>\n",
       "      <td>8.365593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Freq_Of_Word_43</th>\n",
       "      <td>8.148910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Freq_Of_Word_20</th>\n",
       "      <td>7.967795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Freq_Of_Word_14</th>\n",
       "      <td>7.929493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Freq_Of_Word_6</th>\n",
       "      <td>7.593069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Freq_Of_Word_45</th>\n",
       "      <td>7.586417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LengthOFFirstParagraph</th>\n",
       "      <td>7.426806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Freq_Of_Word_28</th>\n",
       "      <td>7.289191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>StylizedLetters</th>\n",
       "      <td>6.883311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Freq_Of_Word_15</th>\n",
       "      <td>6.564920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Freq_Of_Word_17</th>\n",
       "      <td>6.548136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Freq_Of_Word_13</th>\n",
       "      <td>6.519146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Freq_Of_Word_35</th>\n",
       "      <td>6.504486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Freq_Of_Word_9</th>\n",
       "      <td>6.408789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Freq_Of_Word_26</th>\n",
       "      <td>6.256742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Freq_Of_Word_1</th>\n",
       "      <td>5.755947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Freq_Of_Word_5</th>\n",
       "      <td>5.750756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Freq_Of_Word_2</th>\n",
       "      <td>5.554972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Freq_Of_Word_7</th>\n",
       "      <td>5.515214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Freq_Of_Word_23</th>\n",
       "      <td>5.212013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Freq_Of_Word_18</th>\n",
       "      <td>5.151617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Freq_Of_Word_37</th>\n",
       "      <td>5.074108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Freq_Of_Word_16</th>\n",
       "      <td>4.740894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Freq_Of_Word_11</th>\n",
       "      <td>4.625908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Freq_Of_Word_3</th>\n",
       "      <td>3.122382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Freq_Of_Word_12</th>\n",
       "      <td>2.922589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Freq_Of_Word_21</th>\n",
       "      <td>2.419807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Freq_Of_Word_19</th>\n",
       "      <td>1.825404</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Skew\n",
       "Freq_Of_Word_4          36.141607\n",
       "TotalEmojiCharacters    24.140908\n",
       "Freq_Of_Word_48         18.952649\n",
       "Freq_Of_Word_44         15.875713\n",
       "Freq_Of_Word_24         14.662007\n",
       "Freq_Of_Word_8          13.866275\n",
       "Freq_Of_Word_47         12.821998\n",
       "Freq_Of_Word_10         11.965818\n",
       "Freq_Of_Word_49         11.514172\n",
       "Freq_Of_Word_27         10.226667\n",
       "Freq_Of_Word_32         10.193402\n",
       "Freq_Of_Word_34         10.165708\n",
       "Freq_Of_Word_46          9.347865\n",
       "Freq_Of_Word_42          9.263066\n",
       "Freq_Of_Word_40          9.197374\n",
       "Freq_Of_Word_31          9.005282\n",
       "Freq_Of_Word_36          8.969284\n",
       "Freq_Of_Word_22          8.785907\n",
       "Freq_Of_Word_50          8.365593\n",
       "Freq_Of_Word_43          8.148910\n",
       "Freq_Of_Word_20          7.967795\n",
       "Freq_Of_Word_14          7.929493\n",
       "Freq_Of_Word_6           7.593069\n",
       "Freq_Of_Word_45          7.586417\n",
       "LengthOFFirstParagraph   7.426806\n",
       "Freq_Of_Word_28          7.289191\n",
       "StylizedLetters          6.883311\n",
       "Freq_Of_Word_15          6.564920\n",
       "Freq_Of_Word_17          6.548136\n",
       "Freq_Of_Word_13          6.519146\n",
       "Freq_Of_Word_35          6.504486\n",
       "Freq_Of_Word_9           6.408789\n",
       "Freq_Of_Word_26          6.256742\n",
       "Freq_Of_Word_1           5.755947\n",
       "Freq_Of_Word_5           5.750756\n",
       "Freq_Of_Word_2           5.554972\n",
       "Freq_Of_Word_7           5.515214\n",
       "Freq_Of_Word_23          5.212013\n",
       "Freq_Of_Word_18          5.151617\n",
       "Freq_Of_Word_37          5.074108\n",
       "Freq_Of_Word_16          4.740894\n",
       "Freq_Of_Word_11          4.625908\n",
       "Freq_Of_Word_3           3.122382\n",
       "Freq_Of_Word_12          2.922589\n",
       "Freq_Of_Word_21          2.419807\n",
       "Freq_Of_Word_19          1.825404"
      ]
     },
     "execution_count": 1666,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numeric_feats = all_data.dtypes[all_data.dtypes != \"object\"].index\n",
    "\n",
    "# Check the skew of all numerical features\n",
    "skewed_feats = all_data[numeric_feats].apply(lambda x: skew(x.dropna())).sort_values(ascending=False)\n",
    "print(\"\\nSkew in numerical features: \\n\")\n",
    "skewness = pd.DataFrame({'Skew' :skewed_feats})\n",
    "skewness.head(500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1667,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 46 skewed numerical features to Box Cox transform\n"
     ]
    }
   ],
   "source": [
    "skewness = skewness[abs(skewness) > 0.75]\n",
    "print(\"There are {} skewed numerical features to Box Cox transform\".format(skewness.shape[0]))\n",
    "\n",
    "from scipy.special import boxcox1p\n",
    "skewed_features = skewness.index\n",
    "lam = 0.15\n",
    "for feat in skewed_features:\n",
    "    #all_data[feat] += 1\n",
    "    all_data[feat] = boxcox1p(all_data[feat], lam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1650,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1474 entries, 0 to 1473\n",
      "Data columns (total 46 columns):\n",
      "Freq_Of_Word_1            1474 non-null float64\n",
      "Freq_Of_Word_10           1474 non-null float64\n",
      "Freq_Of_Word_11           1474 non-null float64\n",
      "Freq_Of_Word_12           1474 non-null float64\n",
      "Freq_Of_Word_13           1474 non-null float64\n",
      "Freq_Of_Word_14           1474 non-null float64\n",
      "Freq_Of_Word_15           1474 non-null float64\n",
      "Freq_Of_Word_16           1474 non-null float64\n",
      "Freq_Of_Word_17           1474 non-null float64\n",
      "Freq_Of_Word_18           1474 non-null float64\n",
      "Freq_Of_Word_19           1474 non-null float64\n",
      "Freq_Of_Word_2            1474 non-null float64\n",
      "Freq_Of_Word_20           1474 non-null float64\n",
      "Freq_Of_Word_21           1474 non-null float64\n",
      "Freq_Of_Word_22           1474 non-null float64\n",
      "Freq_Of_Word_23           1474 non-null float64\n",
      "Freq_Of_Word_24           1474 non-null float64\n",
      "Freq_Of_Word_26           1474 non-null float64\n",
      "Freq_Of_Word_27           1474 non-null float64\n",
      "Freq_Of_Word_28           1474 non-null float64\n",
      "Freq_Of_Word_3            1474 non-null float64\n",
      "Freq_Of_Word_31           1474 non-null float64\n",
      "Freq_Of_Word_32           1474 non-null float64\n",
      "Freq_Of_Word_34           1474 non-null float64\n",
      "Freq_Of_Word_35           1474 non-null float64\n",
      "Freq_Of_Word_36           1474 non-null float64\n",
      "Freq_Of_Word_37           1474 non-null float64\n",
      "Freq_Of_Word_4            1474 non-null float64\n",
      "Freq_Of_Word_40           1474 non-null float64\n",
      "Freq_Of_Word_42           1474 non-null float64\n",
      "Freq_Of_Word_43           1474 non-null float64\n",
      "Freq_Of_Word_44           1474 non-null float64\n",
      "Freq_Of_Word_45           1474 non-null float64\n",
      "Freq_Of_Word_46           1474 non-null float64\n",
      "Freq_Of_Word_47           1474 non-null float64\n",
      "Freq_Of_Word_48           1474 non-null float64\n",
      "Freq_Of_Word_49           1474 non-null float64\n",
      "Freq_Of_Word_5            1474 non-null float64\n",
      "Freq_Of_Word_50           1474 non-null float64\n",
      "Freq_Of_Word_6            1474 non-null float64\n",
      "Freq_Of_Word_7            1474 non-null float64\n",
      "Freq_Of_Word_8            1474 non-null float64\n",
      "Freq_Of_Word_9            1474 non-null float64\n",
      "LengthOFFirstParagraph    1474 non-null float64\n",
      "StylizedLetters           1474 non-null float64\n",
      "TotalEmojiCharacters      1474 non-null float64\n",
      "dtypes: float64(46)\n",
      "memory usage: 529.8 KB\n"
     ]
    }
   ],
   "source": [
    "all_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1668,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc_X = StandardScaler()\n",
    "all_data = sc_X.fit_transform(all_data)\n",
    "#X_test = sc_X.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1669,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train = all_data[:ntrain]\n",
    "test = all_data[ntrain:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1670,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "train[:] = np.nan_to_num(train)\n",
    "test[:] = np.nan_to_num(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1671,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.savetxt(\"train43.csv\", train, delimiter=\",\")\n",
    "#np.savetxt(\"trainlabel43.csv\", y_train, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1672,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    train, y_train, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1656,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "\n",
    "\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1657,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf1 = xgb.XGBClassifier(colsample_bytree= 0.9,max_depth= 40,n_estimators= 100,class_weight = 'balanced',min_child_weight = 3,subsample= 1,objective = 'binary:logistic')\n",
    "clf2 = LGBMClassifier(random_state=0, n_estimators=100, learning_rate=0.01, num_leaves=31,class_weight = 'balanced')\n",
    "clf3 = RandomForestClassifier(bootstrap= True,max_depth= 30,min_samples_split= 3,n_estimators= 300,class_weight='balanced') \n",
    "clf4 =     MLPClassifier(activation= 'tanh',alpha= 0.0001, hidden_layer_sizes= (200,),learning_rate= 'constant',max_iter= 1000,\n",
    " solver= 'adam')\n",
    "\n",
    "clf5 =     LGBMClassifier(n_jobs=-1,random_state=22,learning_rate=0.1,n_estimators=100,\n",
    "                       colsample_bytree=0.5,num_leaves=70,min_child_samples=20,lambda_l1=1.6,lambda_l2=4,class_weight = 'balanced')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1658,
   "metadata": {},
   "outputs": [],
   "source": [
    "eclf1 = VotingClassifier(estimators=[('lr', clf1), ('rf', clf2), ('gnb', clf3),('lgb',clf5)], voting='soft')\n",
    "eclf1 = eclf1.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1659,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred1 = eclf1.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1432,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_submission = pd.DataFrame({'IsGoodNews': y_pred1})\n",
    "# you could use any filename. We choose submission here\n",
    "my_submission.to_excel('GN.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1660,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mThe Confusion Matrix is: \u001b[0m \n",
      " [[102   7]\n",
      " [  5  76]]\n",
      "\u001b[34mThe Accuracy on Test Set is: \u001b[0m \u001b[34m0.9368421052631579\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from termcolor import colored\n",
    "#from sklearn.cross_validation import KFold\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "#y_pred1 = model.predict(dte)\n",
    "# Making the Confusion Matrix\n",
    "cm = confusion_matrix(y_test, (y_pred1>0.5))\n",
    "print(colored('The Confusion Matrix is: ', 'red'),'\\n', cm)\n",
    "# Calculate the accuracy on test set\n",
    "predict_accuracy_on_test_set = (cm[0,0] + cm[1,1])/(cm[0,0] + cm[1,1]+cm[1,0] + cm[0,1])\n",
    "print(colored('The Accuracy on Test Set is: ', 'blue'), colored(predict_accuracy_on_test_set, 'blue'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1394,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9647058823529412"
      ]
     },
     "execution_count": 1394,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_test,y_pred1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1420,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', class_weight='balanced',\n",
       "       colsample_bylevel=1, colsample_bytree=0.9, gamma=0,\n",
       "       learning_rate=0.1, max_delta_step=0, max_depth=8,\n",
       "       min_child_weight=3, missing=None, n_estimators=100, n_jobs=1,\n",
       "       nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 1420,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1421,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred1 = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1363,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1365,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_submission = pd.DataFrame({'IsGoodNews': y_pred})\n",
    "# you could use any filename. We choose submission here\n",
    "my_submission.to_csv('GN2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1344,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'colsample_bytree': 0.9, 'max_depth': 40, 'n_estimators': 100,'class_weight' : 'balanced', 'min_child_weight': 3, 'subsample': 1,'objective':'binary:logistic','eval_metric':'logloss'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1345,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "dt =xgdmat=xgb.DMatrix(X_train,y_train)\n",
    "dte = xgdmat=xgb.DMatrix(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1346,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-logloss:0.520395\tvalid-logloss:0.545093\n",
      "[200]\ttrain-logloss:0.018885\tvalid-logloss:0.110473\n",
      "[400]\ttrain-logloss:0.015131\tvalid-logloss:0.107392\n",
      "[600]\ttrain-logloss:0.013835\tvalid-logloss:0.109779\n",
      "[800]\ttrain-logloss:0.01315\tvalid-logloss:0.109972\n",
      "[1000]\ttrain-logloss:0.012815\tvalid-logloss:0.110329\n",
      "[1200]\ttrain-logloss:0.012567\tvalid-logloss:0.110147\n",
      "[1400]\ttrain-logloss:0.01235\tvalid-logloss:0.110035\n",
      "[1600]\ttrain-logloss:0.012155\tvalid-logloss:0.109666\n",
      "[1800]\ttrain-logloss:0.011977\tvalid-logloss:0.108702\n",
      "[2000]\ttrain-logloss:0.011813\tvalid-logloss:0.108917\n",
      "[2200]\ttrain-logloss:0.011662\tvalid-logloss:0.109181\n",
      "[2400]\ttrain-logloss:0.01152\tvalid-logloss:0.109903\n",
      "[2600]\ttrain-logloss:0.011389\tvalid-logloss:0.110552\n",
      "[2800]\ttrain-logloss:0.011266\tvalid-logloss:0.111302\n",
      "[2999]\ttrain-logloss:0.011154\tvalid-logloss:0.112473\n"
     ]
    }
   ],
   "source": [
    "model = xgb.train(params, dt, 3000, [(dt, \"train\"),(dte, \"valid\")], verbose_eval=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1422,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mThe Confusion Matrix is: \u001b[0m \n",
      " [[50  2]\n",
      " [ 2 41]]\n",
      "\u001b[34mThe Accuracy on Test Set is: \u001b[0m \u001b[34m0.9578947368421052\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from termcolor import colored\n",
    "#from sklearn.cross_validation import KFold\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "#y_pred1 = model.predict(dte)\n",
    "# Making the Confusion Matrix\n",
    "cm = confusion_matrix(y_test, (y_pred1>0.5))\n",
    "print(colored('The Confusion Matrix is: ', 'red'),'\\n', cm)\n",
    "# Calculate the accuracy on test set\n",
    "predict_accuracy_on_test_set = (cm[0,0] + cm[1,1])/(cm[0,0] + cm[1,1]+cm[1,0] + cm[0,1])\n",
    "print(colored('The Accuracy on Test Set is: ', 'blue'), colored(predict_accuracy_on_test_set, 'blue'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1348,
   "metadata": {},
   "outputs": [],
   "source": [
    "dte = xgdmat=xgb.DMatrix(test)\n",
    "y_pred = model.predict(dte)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1349,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4.92666632e-01, 8.64781614e-04, 1.54170522e-03, 9.64395583e-01,\n",
       "       1.45492051e-02, 9.70189631e-01, 3.75178486e-01, 7.48143315e-01,\n",
       "       9.98792231e-01, 2.69773952e-03, 8.17301452e-01, 9.99734104e-01,\n",
       "       1.28875487e-03, 9.99828219e-01, 4.84502595e-03, 9.96186674e-01,\n",
       "       9.89771336e-02, 9.99442399e-01, 7.83494487e-03, 3.01066251e-03,\n",
       "       5.03421703e-04, 8.77126958e-03, 5.43767062e-04, 4.93229891e-04,\n",
       "       2.67137196e-02, 3.39340448e-01, 9.99879718e-01, 1.23842567e-01,\n",
       "       1.68467755e-04, 9.99858737e-01, 9.00931132e-04, 8.40554130e-04,\n",
       "       5.60844375e-04, 1.31670188e-03, 8.47158226e-05, 9.92735982e-01,\n",
       "       4.94452119e-02, 7.22558677e-01, 9.98969197e-01, 1.74002398e-05,\n",
       "       1.76296075e-04, 7.95420170e-01, 1.48093316e-03, 9.96144533e-01,\n",
       "       9.99470651e-01, 9.99922752e-01, 9.98505592e-01, 8.85541618e-01,\n",
       "       9.50616181e-01, 1.40965328e-01, 8.89646634e-03, 3.47107574e-02,\n",
       "       9.90971565e-01, 6.06385292e-03, 2.88534648e-04, 9.36083376e-01,\n",
       "       1.82461888e-01, 2.59861175e-04, 1.41022261e-02, 3.21236975e-03,\n",
       "       9.99647260e-01, 7.10926426e-04, 5.83252963e-03, 1.50135569e-02,\n",
       "       3.55468201e-03, 8.89181554e-01, 5.71742894e-05, 4.78055000e-01,\n",
       "       4.10045870e-03, 2.40731728e-03, 1.95610240e-01, 9.74852860e-01,\n",
       "       1.28875487e-03, 8.53686869e-01, 4.49936418e-03, 8.95082831e-01,\n",
       "       9.99079943e-01, 2.18104557e-04, 9.60481346e-01, 9.83350933e-01,\n",
       "       3.05282343e-02, 5.06961020e-04, 7.47988652e-03, 4.55333473e-04,\n",
       "       9.99859810e-01, 9.97424364e-01, 2.42764764e-02, 9.99445975e-01,\n",
       "       9.70721781e-01, 2.43230083e-04, 5.00358656e-05, 5.23613319e-02,\n",
       "       3.40710208e-02, 3.10434611e-03, 9.91987824e-01, 9.94479299e-01,\n",
       "       2.35572662e-02, 3.29893362e-03, 9.98797297e-01, 2.72480119e-03,\n",
       "       3.62349907e-04, 9.60862458e-01, 1.98905822e-03, 4.43704799e-03,\n",
       "       1.13084625e-05, 5.81577560e-03, 9.99853373e-01, 6.85778141e-01,\n",
       "       9.99923229e-01, 9.97115254e-01, 1.46318246e-02, 9.98702884e-01,\n",
       "       5.78521825e-02, 7.13328971e-03, 2.35139072e-01, 8.44761496e-04,\n",
       "       9.23145446e-04, 9.93676722e-01, 9.99860764e-01, 3.01055097e-05,\n",
       "       9.34861839e-01, 1.61174074e-04, 9.79095474e-02, 9.98932898e-01,\n",
       "       1.65686086e-02, 6.24199864e-03, 4.57341084e-03, 3.69115872e-03,\n",
       "       9.99948978e-01, 2.82595120e-02, 7.72449225e-02, 9.99811232e-01,\n",
       "       9.99495029e-01, 7.23854220e-03, 7.02111125e-01, 9.97826636e-01,\n",
       "       5.38838576e-05, 9.97547448e-01, 9.97730315e-01, 9.49227154e-01,\n",
       "       2.83919666e-02, 1.20635955e-02, 1.29874907e-02, 8.54807254e-03,\n",
       "       9.99237776e-01, 4.99499403e-03, 1.42689445e-03, 9.95198429e-01,\n",
       "       5.94546413e-03, 2.98687886e-03, 2.59177061e-03, 9.99889731e-01,\n",
       "       2.11978302e-04, 3.39340448e-01, 7.55027030e-03, 5.97561803e-03,\n",
       "       2.94775527e-04, 1.81503303e-03, 9.99262750e-01, 9.95829999e-01,\n",
       "       8.21220160e-01, 1.95982144e-03, 1.05679804e-03, 1.29561210e-02,\n",
       "       1.08149916e-05, 5.84417861e-03, 4.11647110e-04, 9.03687396e-06,\n",
       "       9.56800759e-01, 2.23576147e-02, 9.96454954e-01, 6.16916828e-02,\n",
       "       1.01241969e-01, 9.93572474e-01, 9.99938130e-01, 2.63889530e-03,\n",
       "       9.97659564e-01, 9.09303665e-01, 9.79321778e-01, 7.27232778e-03,\n",
       "       9.96709228e-01, 3.95627576e-05, 9.99495387e-01, 2.52101682e-02,\n",
       "       1.07972824e-04, 2.86075010e-05, 2.60424777e-03, 1.84782536e-03,\n",
       "       6.41849041e-01, 1.96930379e-01, 2.07430217e-03, 9.99178469e-01,\n",
       "       9.79872346e-01, 9.99828219e-01, 9.99958634e-01, 8.46935203e-04,\n",
       "       1.52833323e-04, 6.08719528e-01, 9.95958388e-01, 1.99747637e-01,\n",
       "       1.66154299e-02, 7.43248034e-04, 3.32452469e-02, 2.87663215e-03,\n",
       "       9.97510552e-01, 2.89932173e-03, 7.74677694e-01, 4.41541888e-05,\n",
       "       9.99929190e-01, 4.22709696e-02, 7.88704753e-02, 1.28829330e-02,\n",
       "       2.11888982e-04, 9.99534130e-01, 1.64089680e-01, 6.22237325e-01,\n",
       "       9.90210176e-01, 5.01663201e-02, 1.66486643e-04, 4.80286719e-04,\n",
       "       2.15384379e-01, 4.37496201e-04, 3.62917185e-02, 1.80376205e-03,\n",
       "       9.76731884e-04, 5.25611997e-01, 1.63129661e-02, 1.81444269e-02,\n",
       "       1.91885903e-02, 1.67645223e-03, 5.38060069e-03, 1.01468126e-04,\n",
       "       9.94320035e-01, 1.13277941e-03, 1.47805251e-02, 6.44710963e-05,\n",
       "       4.27460251e-03, 9.99951720e-01, 9.16141726e-04, 1.30983710e-03,\n",
       "       5.94117194e-02, 6.84460392e-03, 8.78108852e-03, 9.15494382e-01,\n",
       "       2.45859544e-03, 9.99929070e-01, 9.97846127e-01, 1.52386981e-03,\n",
       "       5.46834655e-02, 9.07874841e-04, 8.24061096e-01, 9.99346673e-01,\n",
       "       7.85174906e-01, 9.98217404e-01, 3.90958004e-02, 9.07033216e-04,\n",
       "       2.08782647e-02, 7.68713832e-01, 9.84333336e-01, 1.32442608e-01,\n",
       "       1.41882198e-03, 1.45333260e-03, 9.81886506e-01, 4.17911589e-01,\n",
       "       1.49591025e-02, 1.26363412e-01, 9.93429720e-01, 9.97871161e-01,\n",
       "       3.66621534e-04, 3.14712233e-05, 4.99015441e-03, 5.64356218e-04,\n",
       "       4.92087938e-02, 2.96741277e-02, 6.11732574e-03, 7.20751414e-05,\n",
       "       6.89006984e-01, 9.99406934e-01, 9.99538898e-01, 4.92990330e-05,\n",
       "       2.68887030e-03, 7.33060949e-03, 1.00083766e-03, 1.21767062e-03,\n",
       "       9.99892592e-01, 1.87513694e-01, 9.99679685e-01, 9.11945760e-01,\n",
       "       6.57664321e-04, 1.16182596e-03, 4.53745782e-01, 4.44989372e-03,\n",
       "       1.32606208e-01, 3.32682277e-04, 4.31784317e-02, 1.97325906e-04,\n",
       "       9.99584854e-01, 9.97642696e-01, 9.99795020e-01, 1.20457662e-04,\n",
       "       9.40547267e-04, 9.91359890e-01, 9.71888840e-01, 2.26145089e-02,\n",
       "       1.13252585e-03, 1.20901945e-03, 3.56574021e-02, 7.43295372e-01,\n",
       "       7.51609623e-04, 9.99929070e-01, 4.54271445e-03, 1.38625596e-02,\n",
       "       9.99382734e-01, 4.90044802e-03, 4.86612394e-02, 9.84552145e-01,\n",
       "       9.78449643e-01, 3.34018492e-03, 1.37595618e-02, 9.62365389e-01,\n",
       "       1.34558575e-02, 9.87057626e-01, 9.86113009e-05, 1.21733741e-04,\n",
       "       3.81624758e-01, 9.93466437e-01, 9.76795033e-02, 2.90142484e-02,\n",
       "       9.99684453e-01, 2.10648119e-01, 9.99870777e-01, 1.28945662e-03,\n",
       "       2.30489695e-03, 3.23323038e-04, 9.94244039e-01, 8.45826289e-04,\n",
       "       3.23323038e-04, 2.70517834e-04, 9.97258782e-01, 9.97920573e-01,\n",
       "       4.09875158e-03, 2.41871819e-01, 9.95964289e-01, 3.76963243e-02,\n",
       "       9.99662519e-01, 2.83110905e-02, 9.68697423e-04, 7.61900679e-04,\n",
       "       1.52126711e-04, 9.15130496e-01, 1.83662283e-04, 4.38306481e-02,\n",
       "       1.74831669e-03, 2.46244599e-04, 7.68713832e-01, 9.97349024e-01,\n",
       "       9.99443948e-01, 9.98388603e-03, 9.99536395e-01, 5.90789199e-01,\n",
       "       1.63830630e-03, 2.21060719e-02, 1.98905822e-03, 9.20014739e-01,\n",
       "       9.86523986e-01, 2.01341119e-02, 2.44902796e-03, 1.17618556e-03,\n",
       "       9.96041894e-01, 6.88119675e-04, 9.85429347e-01, 9.99583900e-01,\n",
       "       9.99927282e-01, 1.51484925e-03, 7.91065031e-05, 2.95965839e-03,\n",
       "       3.60524189e-03, 4.88843629e-03, 3.20566935e-03, 3.65467719e-03,\n",
       "       4.73196211e-04, 9.79778767e-01, 9.99989033e-01, 9.95308697e-01,\n",
       "       4.24386650e-01, 2.24966351e-02, 1.12593101e-04, 3.28362912e-01,\n",
       "       9.99458730e-01, 2.84751586e-04, 2.47083255e-03, 5.96415997e-01,\n",
       "       1.35534048e-01, 3.84564373e-05, 9.98610139e-01, 9.85709548e-01,\n",
       "       9.87944245e-01, 3.46345939e-02, 8.30271965e-05, 2.96991311e-05,\n",
       "       6.69438124e-01, 9.97184217e-01, 1.57206290e-04, 3.02291699e-02,\n",
       "       9.40664947e-01, 3.66396443e-06, 3.82439257e-03, 3.91605485e-04,\n",
       "       7.14175124e-03, 1.84333127e-03, 1.58623478e-03, 8.08930278e-01,\n",
       "       8.62108096e-02, 7.57207803e-04, 1.59810722e-01, 1.95659511e-03,\n",
       "       5.50157747e-05, 1.42253404e-02, 3.41601414e-03, 3.02517354e-01,\n",
       "       9.92396414e-01, 9.98684585e-01, 9.97332454e-01, 1.52524898e-03,\n",
       "       9.99795020e-01, 4.23366949e-03, 9.99637604e-01, 7.07373470e-02,\n",
       "       6.62904698e-03, 2.05446791e-04, 1.40706040e-02, 3.49281915e-02,\n",
       "       2.86935598e-01, 6.12741744e-04, 8.29891086e-01, 9.77236867e-01,\n",
       "       8.40154884e-04, 9.49214578e-01, 1.10325627e-01, 3.10300326e-04,\n",
       "       9.98051763e-01, 1.58623478e-03, 9.99785364e-01, 1.27885908e-01,\n",
       "       5.81947416e-02, 4.78278787e-04, 8.00929614e-04, 9.93293747e-02,\n",
       "       1.93952639e-02, 7.09168016e-05, 9.98275161e-01, 9.99755919e-01,\n",
       "       4.01006080e-03, 1.72084533e-02, 9.98051167e-01, 3.09353858e-01,\n",
       "       6.93195090e-02, 1.28602341e-01, 1.49254469e-04, 9.38935041e-01,\n",
       "       4.84439790e-01, 5.56333549e-02, 1.11079346e-02, 1.71400505e-04,\n",
       "       9.99050319e-01, 1.48279581e-03, 9.70275700e-01, 4.91903513e-04,\n",
       "       6.79878722e-05, 3.22269559e-01, 1.66311301e-02, 1.91718354e-05,\n",
       "       3.11092101e-02, 9.92873311e-01, 8.10878217e-01, 8.24061096e-01,\n",
       "       9.27351415e-03, 9.53864492e-03, 3.67205292e-01, 9.73965585e-01,\n",
       "       1.01434090e-03, 3.22143984e-04, 4.19566005e-01, 9.99703705e-01,\n",
       "       2.14577075e-02, 2.84929178e-03, 5.17890692e-01, 4.85812983e-04,\n",
       "       9.98641908e-01, 1.79356313e-03, 4.47009807e-04, 7.92736113e-01,\n",
       "       9.26253080e-01, 9.99634743e-01, 9.99751866e-01, 1.21468436e-02,\n",
       "       1.78989838e-03, 1.63754751e-03, 3.69158830e-03, 3.30477720e-03,\n",
       "       8.89657855e-01, 9.78610933e-01, 9.09303665e-01, 5.91626624e-03,\n",
       "       4.45752442e-02, 1.28012348e-03, 2.15526551e-01, 1.43034942e-03,\n",
       "       6.99784830e-02, 6.51602866e-04, 9.88524377e-01, 2.36538914e-03,\n",
       "       2.50366563e-03, 9.99585807e-01, 9.98637617e-01, 8.83143067e-01,\n",
       "       4.17396337e-01, 9.97582078e-01, 2.69696474e-01, 7.86184147e-03,\n",
       "       9.66795921e-01, 9.10116076e-01, 1.35407597e-03, 9.28863168e-01,\n",
       "       1.99634419e-03, 2.44568684e-03, 1.41797498e-01], dtype=float32)"
      ]
     },
     "execution_count": 1349,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1190,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_submission = pd.DataFrame({'IsGoodNews': y_pred})\n",
    "# you could use any filename. We choose submission here\n",
    "my_submission.to_csv('GN1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1213,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from vecstack import stacking\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "import lightgbm as lgbClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1217,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    LGBMClassifier(random_state=0,subsample= 0.9510118790770111, n_estimators=720,min_child_samples= 97, learning_rate=0.01, num_leaves=14,class_weight= 'balanced', colsample_bytree=  0.9221304051471293),\n",
    "    \n",
    "\n",
    "\n",
    "        \n",
    "    \n",
    "    #ExtraTreesClassifier(bootstrap= True,max_depth= 90,max_leaf_nodes= 9,min_samples_leaf= 3,min_samples_split= 12,n_estimators= 500,oob_score= True),\n",
    "    \n",
    "    #GradientBoostingClassifier(n_estimators=500,max_depth=50,min_samples_split=5),\n",
    "    RandomForestClassifier(bootstrap= True,\n",
    " max_depth= 25,\n",
    " #max_features= 10,\n",
    "# min_samples_leaf= 3,\n",
    " min_samples_split= 3,\n",
    " n_estimators= 300),\n",
    "    #DecisionTreeClassifier(max_depth= 12, max_leaf_nodes= 11, min_samples_split= 2),\n",
    "    \n",
    "    MLPClassifier(activation= 'tanh',\n",
    " alpha= 0.0001,\n",
    " hidden_layer_sizes= (200,),\n",
    " learning_rate= 'constant',\n",
    " max_iter= 1000,\n",
    " solver= 'adam'),\n",
    "    RandomForestClassifier(random_state=0, max_depth=25, n_estimators=1000, n_jobs=4, class_weight={0:0.38, 1:0.62}),\n",
    "    \n",
    "    xgb.XGBClassifier(colsample_bytree= 0.9,max_depth= 8,n_estimators= 500,reg_alpha= 0.03,subsample= 0.999),\n",
    "    #LogisticRegression(C=1,penalty='l2'),\n",
    "    LGBMClassifier(random_state=0, n_estimators=520, learning_rate=0.01, num_leaves=31,scale_pos_weight=2),\n",
    "    LGBMClassifier(n_jobs=-1,random_state=22,learning_rate=0.1,n_estimators=100,\n",
    "                       colsample_bytree=0.5,num_leaves=70,min_child_samples=20,lambda_l1=1.6,lambda_l2=4),\n",
    "    \n",
    "    \n",
    "    #KNeighborsClassifier(metric =  'euclidean', n_neighbors= 7, weights= 'distance'),\n",
    "   # LogisticRegression(),\n",
    "   # SVC(C=10,gamma = 0.0001)\n",
    "    \n",
    "    \n",
    "    \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "task:         [classification]\n",
      "n_classes:    [2]\n",
      "metric:       [accuracy_score]\n",
      "mode:         [oof_pred_bag]\n",
      "n_models:     [7]\n",
      "\n",
      "model  0:     [LGBMClassifier]\n",
      "    fold  0:  [0.88421053]\n",
      "    fold  1:  [0.86267606]\n",
      "    fold  2:  [0.90106007]\n",
      "    ----\n",
      "    MEAN:     [0.88264888] + [0.01570907]\n",
      "    FULL:     [0.88262911]\n",
      "\n",
      "model  1:     [RandomForestClassifier]\n",
      "    fold  0:  [0.91929825]\n",
      "    fold  1:  [0.88028169]\n",
      "    fold  2:  [0.91519435]\n",
      "    ----\n",
      "    MEAN:     [0.90492476] + [0.01750564]\n",
      "    FULL:     [0.90492958]\n",
      "\n",
      "model  2:     [MLPClassifier]\n",
      "    fold  0:  [0.89473684]\n",
      "    fold  1:  [0.88380282]\n",
      "    fold  2:  [0.91872792]\n",
      "    ----\n",
      "    MEAN:     [0.89908919] + [0.01458647]\n",
      "    FULL:     [0.89906103]\n",
      "\n",
      "model  3:     [RandomForestClassifier]\n",
      "    fold  0:  [0.91228070]\n",
      "    fold  1:  [0.87676056]\n",
      "    fold  2:  [0.91872792]\n",
      "    ----\n",
      "    MEAN:     [0.90258973] + [0.01845266]\n",
      "    FULL:     [0.90258216]\n",
      "\n",
      "model  4:     [XGBClassifier]\n",
      "    fold  0:  [0.91228070]\n",
      "    fold  1:  [0.88732394]\n",
      "    fold  2:  [0.90812721]\n",
      "    ----\n",
      "    MEAN:     [0.90257728] + [0.01091822]\n",
      "    FULL:     [0.90258216]\n",
      "\n",
      "model  5:     [LGBMClassifier]\n",
      "    fold  0:  [0.92280702]\n",
      "    fold  1:  [0.88380282]\n",
      "    fold  2:  [0.91519435]\n",
      "    ----\n",
      "    MEAN:     [0.90726806] + [0.01688098]\n",
      "    FULL:     [0.90727700]\n",
      "\n",
      "model  6:     [LGBMClassifier]\n",
      "    fold  0:  [0.90877193]\n",
      "    fold  1:  [0.87676056]\n",
      "    fold  2:  [0.92579505]\n",
      "    ----\n",
      "    MEAN:     [0.90377585] + [0.02032758]\n",
      "    FULL:     [0.90375587]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "S_train, S_test = stacking(models,                     # list of models\n",
    "                           X_train, y_train, test,   # data\n",
    "                           regression=False,           # classification task (if you need \n",
    "                                                       #     regression - set to True)\n",
    "                           mode='oof_pred_bag',        # mode: oof for train set, predict test \n",
    "                                                       #     set in each fold and vote\n",
    "                           needs_proba=False,          # predict class labels (if you need \n",
    "                                                       #     probabilities - set to True) \n",
    "                           save_dir=None,              # do not save result and log (to save \n",
    "                                                       #     in current dir - set to '.')\n",
    "                           metric=accuracy_score,      # metric: callable\n",
    "                           n_folds=3,                  # number of folds\n",
    "                           stratified=True,            # stratified split for folds\n",
    "                           shuffle=True,               # shuffle the data\n",
    "                           random_state=0,             # ensure reproducibility\n",
    "                           verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1219,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(\"ens_4.csv\", S_test, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 1, ..., 1, 1, 1],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [1, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 1221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1220,
   "metadata": {},
   "outputs": [],
   "source": [
    "#txt(\"train43.csv\", S_train, delimiter=\",\")\n",
    "#np.savetxt(\"trainlabel43.csv\", y_train, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1063,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier(n_estimators=300,class_weight='balanced')\n",
    "# Fit 2nd level model\n",
    "model = model.fit(S_train, y_train)\n",
    "\n",
    "# Predict\n",
    "y_pred = model.predict(S_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 949,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mThe Confusion Matrix is: \u001b[0m \n",
      " [[107   2]\n",
      " [  5  76]]\n",
      "\u001b[34mThe Accuracy on Test Set is: \u001b[0m \u001b[34m0.9631578947368421\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from termcolor import colored\n",
    "#from sklearn.cross_validation import KFold\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "#y_pred1 = model.predict(dte)\n",
    "# Making the Confusion Matrix\n",
    "cm = confusion_matrix(y_test, (y_pred>0.5))\n",
    "print(colored('The Confusion Matrix is: ', 'red'),'\\n', cm)\n",
    "# Calculate the accuracy on test set\n",
    "predict_accuracy_on_test_set = (cm[0,0] + cm[1,1])/(cm[0,0] + cm[1,1]+cm[1,0] + cm[0,1])\n",
    "print(colored('The Accuracy on Test Set is: ', 'blue'), colored(predict_accuracy_on_test_set, 'blue'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 921,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1,\n",
       "       1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1,\n",
       "       0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1,\n",
       "       1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0,\n",
       "       0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0,\n",
       "       1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1,\n",
       "       1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0,\n",
       "       0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0,\n",
       "       0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0,\n",
       "       1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1,\n",
       "       0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0,\n",
       "       1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0,\n",
       "       0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1,\n",
       "       1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0,\n",
       "       1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0,\n",
       "       0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1,\n",
       "       0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0,\n",
       "       0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 921,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1065,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_submission = pd.DataFrame({'IsGoodNews': y_pred})\n",
    "# you could use any filename. We choose submission here\n",
    "my_submission.to_csv('GN_N.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mThe Confusion Matrix is: \u001b[0m \n",
      " [[51  1]\n",
      " [ 4 39]]\n",
      "\u001b[34mThe Accuracy on Test Set is: \u001b[0m \u001b[34m0.9473684210526315\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from termcolor import colored\n",
    "#from sklearn.cross_validation import KFold\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "#y_pred1 = model.predict(dte)\n",
    "# Making the Confusion Matrix\n",
    "cm = confusion_matrix(y_test, (y_pred>0.5))\n",
    "print(colored('The Confusion Matrix is: ', 'red'),'\\n', cm)\n",
    "# Calculate the accuracy on test set\n",
    "predict_accuracy_on_test_set = (cm[0,0] + cm[1,1])/(cm[0,0] + cm[1,1]+cm[1,0] + cm[0,1])\n",
    "print(colored('The Accuracy on Test Set is: ', 'blue'), colored(predict_accuracy_on_test_set, 'blue'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 710,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(\"goodnews_ens.csv\", np.round(y_pred), delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'colsample_bytree': 0.8,'learning_rate': 0.0003, 'max_depth': 8, 'n_estimators': 1000, 'subsample': 1,'scale_pos_weight':4,'objective':'binary:logistic','eval_metric':'logloss'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "dt =xgdmat=xgb.DMatrix(S_train,y_train)\n",
    "dte = xgdmat=xgb.DMatrix(S_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "ename": "XGBoostError",
     "evalue": "b'[21:11:51] C:/Users/Administrator/Desktop/xgboost/src/metric/elementwise_metric.cu:341: Check failed: info.labels_.Size() != 0U (0 vs. 0) label set cannot be empty'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mXGBoostError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-303-7d7ed6bb774b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mxgb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2000\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"train\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdte\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"valid\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose_eval\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m200\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\xgboost\\training.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, learning_rates)\u001b[0m\n\u001b[0;32m    214\u001b[0m                            \u001b[0mevals\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mevals\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    215\u001b[0m                            \u001b[0mobj\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 216\u001b[1;33m                            xgb_model=xgb_model, callbacks=callbacks)\n\u001b[0m\u001b[0;32m    217\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    218\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\xgboost\\training.py\u001b[0m in \u001b[0;36m_train_internal\u001b[1;34m(params, dtrain, num_boost_round, evals, obj, feval, xgb_model, callbacks)\u001b[0m\n\u001b[0;32m     82\u001b[0m         \u001b[1;31m# check evaluation result.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     83\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevals\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 84\u001b[1;33m             \u001b[0mbst_eval_set\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbst\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval_set\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     85\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbst_eval_set\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSTRING_TYPES\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m                 \u001b[0mmsg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbst_eval_set\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\xgboost\\core.py\u001b[0m in \u001b[0;36meval_set\u001b[1;34m(self, evals, iteration, feval)\u001b[0m\n\u001b[0;32m   1171\u001b[0m                                               \u001b[0mdmats\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevnames\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1172\u001b[0m                                               \u001b[0mc_bst_ulong\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1173\u001b[1;33m                                               ctypes.byref(msg)))\n\u001b[0m\u001b[0;32m   1174\u001b[0m         \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmsg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1175\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mfeval\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\xgboost\\core.py\u001b[0m in \u001b[0;36m_check_call\u001b[1;34m(ret)\u001b[0m\n\u001b[0;32m    176\u001b[0m     \"\"\"\n\u001b[0;32m    177\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 178\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mXGBoostError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_LIB\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mXGBGetLastError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    179\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    180\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mXGBoostError\u001b[0m: b'[21:11:51] C:/Users/Administrator/Desktop/xgboost/src/metric/elementwise_metric.cu:341: Check failed: info.labels_.Size() != 0U (0 vs. 0) label set cannot be empty'"
     ]
    }
   ],
   "source": [
    "model = xgb.train(params, dt, 2000, [(dt, \"train\"),(dte, \"valid\")], verbose_eval=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mThe Confusion Matrix is: \u001b[0m \n",
      " [[45  7]\n",
      " [ 4 39]]\n",
      "\u001b[34mThe Accuracy on Test Set is: \u001b[0m \u001b[34m0.8842105263157894\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from termcolor import colored\n",
    "#from sklearn.cross_validation import KFold\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "y_pred1 = model.predict(dte)\n",
    "# Making the Confusion Matrix\n",
    "cm = confusion_matrix(y_test, (y_pred1>0.5))\n",
    "print(colored('The Confusion Matrix is: ', 'red'),'\\n', cm)\n",
    "# Calculate the accuracy on test set\n",
    "predict_accuracy_on_test_set = (cm[0,0] + cm[1,1])/(cm[0,0] + cm[1,1]+cm[1,0] + cm[0,1])\n",
    "print(colored('The Accuracy on Test Set is: ', 'blue'), colored(predict_accuracy_on_test_set, 'blue'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtest = xgdmat=xgb.DMatrix(test)\n",
    "y_pred = model.predict(dtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(\"goodnews.csv\", np.round(y_pred), delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 527 entries, 947 to 1473\n",
      "Data columns (total 53 columns):\n",
      "Freq_Of_Word_1            527 non-null float64\n",
      "Freq_Of_Word_10           527 non-null float64\n",
      "Freq_Of_Word_11           527 non-null float64\n",
      "Freq_Of_Word_12           527 non-null float64\n",
      "Freq_Of_Word_13           527 non-null float64\n",
      "Freq_Of_Word_14           527 non-null float64\n",
      "Freq_Of_Word_15           527 non-null float64\n",
      "Freq_Of_Word_16           527 non-null float64\n",
      "Freq_Of_Word_17           527 non-null float64\n",
      "Freq_Of_Word_18           527 non-null float64\n",
      "Freq_Of_Word_19           527 non-null float64\n",
      "Freq_Of_Word_2            527 non-null float64\n",
      "Freq_Of_Word_20           527 non-null float64\n",
      "Freq_Of_Word_21           527 non-null float64\n",
      "Freq_Of_Word_22           527 non-null float64\n",
      "Freq_Of_Word_23           527 non-null float64\n",
      "Freq_Of_Word_24           527 non-null float64\n",
      "Freq_Of_Word_25           527 non-null float64\n",
      "Freq_Of_Word_26           527 non-null float64\n",
      "Freq_Of_Word_27           527 non-null float64\n",
      "Freq_Of_Word_28           527 non-null float64\n",
      "Freq_Of_Word_29           527 non-null float64\n",
      "Freq_Of_Word_3            527 non-null float64\n",
      "Freq_Of_Word_30           527 non-null float64\n",
      "Freq_Of_Word_31           527 non-null float64\n",
      "Freq_Of_Word_32           527 non-null float64\n",
      "Freq_Of_Word_33           527 non-null float64\n",
      "Freq_Of_Word_34           527 non-null float64\n",
      "Freq_Of_Word_35           527 non-null float64\n",
      "Freq_Of_Word_36           527 non-null float64\n",
      "Freq_Of_Word_37           527 non-null float64\n",
      "Freq_Of_Word_38           527 non-null float64\n",
      "Freq_Of_Word_39           527 non-null float64\n",
      "Freq_Of_Word_4            527 non-null float64\n",
      "Freq_Of_Word_40           527 non-null float64\n",
      "Freq_Of_Word_41           527 non-null float64\n",
      "Freq_Of_Word_42           527 non-null float64\n",
      "Freq_Of_Word_43           527 non-null float64\n",
      "Freq_Of_Word_44           527 non-null float64\n",
      "Freq_Of_Word_45           527 non-null float64\n",
      "Freq_Of_Word_46           527 non-null float64\n",
      "Freq_Of_Word_47           527 non-null float64\n",
      "Freq_Of_Word_48           527 non-null float64\n",
      "Freq_Of_Word_49           527 non-null float64\n",
      "Freq_Of_Word_5            527 non-null float64\n",
      "Freq_Of_Word_50           527 non-null float64\n",
      "Freq_Of_Word_6            527 non-null float64\n",
      "Freq_Of_Word_7            527 non-null float64\n",
      "Freq_Of_Word_8            527 non-null float64\n",
      "Freq_Of_Word_9            527 non-null float64\n",
      "LengthOFFirstParagraph    527 non-null float64\n",
      "StylizedLetters           527 non-null float64\n",
      "TotalEmojiCharacters      527 non-null float64\n",
      "dtypes: float64(53)\n",
      "memory usage: 218.3 KB\n"
     ]
    }
   ],
   "source": [
    "test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 1., 0., 0., 1., 1., 1., 0., 0., 1., 0., 1., 0., 1., 0.,\n",
       "       1., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 1., 0., 0., 0., 0.,\n",
       "       0., 1., 0., 1., 1., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1.,\n",
       "       0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0.,\n",
       "       0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1., 1., 0., 0., 0., 0., 1.,\n",
       "       1., 0., 1., 1., 0., 0., 0., 0., 0., 1., 1., 0., 0., 1., 0., 0., 1.,\n",
       "       0., 1., 0., 0., 1., 0., 1., 1., 0., 1., 0., 0., 1., 0., 0., 1., 1.,\n",
       "       0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 1., 1., 0., 0., 1.,\n",
       "       0., 1., 1., 1., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1., 0.,\n",
       "       1., 0., 0., 0., 0., 1., 1., 1., 0., 0., 1., 0., 0., 0., 0., 1., 0.,\n",
       "       1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 0., 0., 0., 0.,\n",
       "       0., 0., 1., 0., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 0., 0., 0.,\n",
       "       1., 0., 0., 0., 1., 1., 1., 0., 0., 1., 1., 0., 1., 0., 0., 0., 1.,\n",
       "       0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1.,\n",
       "       0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0.,\n",
       "       0., 0., 1., 1., 0., 0., 0., 1., 1., 0., 0., 1., 1., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 0.,\n",
       "       0., 1., 0., 0., 0., 0., 0., 1., 1., 1., 0., 0., 1., 1., 0., 0., 0.,\n",
       "       0., 1., 0., 1., 0., 0., 1., 0., 0., 1., 1., 0., 0., 1., 0., 1., 0.,\n",
       "       0., 0., 1., 0., 0., 1., 1., 1., 0., 0., 0., 1., 0., 0., 0., 1., 1.,\n",
       "       0., 0., 1., 0., 1., 1., 0., 0., 0., 1., 0., 1., 0., 0., 1., 1., 1.,\n",
       "       0., 1., 1., 0., 0., 0., 1., 1., 0., 0., 0., 1., 0., 1., 1., 1., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 0., 0., 0., 1., 1., 0., 0.,\n",
       "       1., 0., 0., 1., 1., 1., 0., 0., 0., 1., 1., 0., 0., 1., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 0., 1.,\n",
       "       0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 1., 0., 0., 1., 0.,\n",
       "       1., 1., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 1., 0., 1., 0.,\n",
       "       1., 0., 0., 0., 0., 1., 0., 1., 0., 0., 1., 0., 0., 0., 1., 0., 1.,\n",
       "       0., 0., 0., 1., 0., 0., 1., 1., 0., 0., 0., 0., 1., 0., 0., 1., 1.,\n",
       "       1., 1., 0., 0., 0., 0., 0., 1., 1., 1., 0., 1., 0., 0., 0., 0., 0.,\n",
       "       1., 0., 0., 1., 1., 0., 0., 1., 0., 0., 1., 1., 0., 1., 0., 0., 0.],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1639,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from matplotlib import pyplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1640,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most important features: [7, 46, 13, 39, 45, 42, 47, 18, 17, 16, 21, 40, 10, 1, 9, 12, 35, 41, 38, 15, 3, 34, 33, 6, 4, 8, 43, 0, 31, 28, 19, 2, 11, 44, 5, 27, 22, 32, 23, 30, 37, 14, 20, 26, 25, 24, 29, 36]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rlee3104\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "#from sklearn.linear_model import LinearRegression\n",
    "model = RandomForestClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "importance = model.feature_importances_\n",
    "#for i,v in enumerate(importance):\n",
    "#\tprint('Feature: %0d, Score: %.5f' % (i,v))\n",
    "# plot feature importance\n",
    "#pyplot.bar([x for x in range(len(importance))], importance)\n",
    "#pyplot.show()\n",
    "\n",
    "\n",
    "\n",
    "important_features_dict = {}\n",
    "for x,i in enumerate(model.feature_importances_):\n",
    "    \n",
    "    important_features_dict[x]=i\n",
    "\n",
    "\n",
    "important_features_list = sorted(important_features_dict,\n",
    "                                 key=important_features_dict.get,\n",
    "                                 reverse=True)\n",
    "\n",
    "print ('Most important features: %s' %important_features_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1641,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature: 0, Score: 0.00446\n",
      "Feature: 1, Score: 0.02725\n",
      "Feature: 2, Score: 0.00847\n",
      "Feature: 3, Score: 0.01561\n",
      "Feature: 4, Score: 0.00875\n",
      "Feature: 5, Score: 0.00269\n",
      "Feature: 6, Score: 0.00066\n",
      "Feature: 7, Score: 0.06484\n",
      "Feature: 8, Score: 0.01314\n",
      "Feature: 9, Score: 0.00883\n",
      "Feature: 10, Score: 0.03552\n",
      "Feature: 11, Score: 0.00428\n",
      "Feature: 12, Score: 0.00519\n",
      "Feature: 13, Score: 0.08554\n",
      "Feature: 14, Score: 0.00195\n",
      "Feature: 15, Score: 0.01266\n",
      "Feature: 16, Score: 0.05791\n",
      "Feature: 17, Score: 0.03233\n",
      "Feature: 18, Score: 0.03057\n",
      "Feature: 19, Score: 0.00839\n",
      "Feature: 20, Score: 0.00448\n",
      "Feature: 21, Score: 0.03706\n",
      "Feature: 22, Score: 0.00491\n",
      "Feature: 23, Score: 0.00150\n",
      "Feature: 24, Score: 0.00000\n",
      "Feature: 25, Score: 0.00154\n",
      "Feature: 26, Score: 0.00692\n",
      "Feature: 27, Score: 0.00367\n",
      "Feature: 28, Score: 0.00886\n",
      "Feature: 29, Score: 0.00000\n",
      "Feature: 30, Score: 0.00000\n",
      "Feature: 31, Score: 0.00974\n",
      "Feature: 32, Score: 0.00121\n",
      "Feature: 33, Score: 0.00188\n",
      "Feature: 34, Score: 0.02062\n",
      "Feature: 35, Score: 0.01355\n",
      "Feature: 36, Score: 0.00095\n",
      "Feature: 37, Score: 0.00073\n",
      "Feature: 38, Score: 0.00382\n",
      "Feature: 39, Score: 0.04955\n",
      "Feature: 40, Score: 0.01352\n",
      "Feature: 41, Score: 0.02276\n",
      "Feature: 42, Score: 0.11902\n",
      "Feature: 43, Score: 0.02039\n",
      "Feature: 44, Score: 0.02140\n",
      "Feature: 45, Score: 0.06887\n",
      "Feature: 46, Score: 0.06281\n",
      "Feature: 47, Score: 0.07119\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rlee3104\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "model = RandomForestClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "importance = model.feature_importances_\n",
    "for i,v in enumerate(importance):\n",
    "    \n",
    "\tprint('Feature: %0d, Score: %.5f' % (i,v))\n",
    "#plot feature importance\n",
    "pyplot.bar([x for x in range(len(importance))], importance)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1223,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = pd.read_csv('ens_4.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1224,
   "metadata": {},
   "outputs": [],
   "source": [
    "excel = q['L']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1226,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(\"excel_NEW.csv\", excel, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
