# ML_Hackathons
Some of the hackathons i took part in over the summer
DATA_HACK_COMPETITION -: Analytics vidhya organized a student hackathon for machine learning enthusiasts. This was my first hackathon and I took part in it during my end sem exams(DATA_HACK_COMPETITON) and used my knowloedge of ensemble learners for this classification problem.
To look back upon I can spot many changes in it that couldhave made me finish in the top 50
I finished 187 out of the total 1100 registered participants
datahackbetter-: After going through my first Udacity project I implemented the same problem using a neural network in keras achieving an accuracy of 68% in hidden test set 


# American Express Artificial intelligence Problem statement 2
I came to know of this event on the last day of the competition itself with a little more than 10hrs remaining but still managed to recieve an overall accuracy of 91.8% with the highest being 96%
https://www.hackerearth.com/challenge/hiring/ai-problem-statement-2/leaderboard/
username -: rohan7797
I used xgboost and baesian optimization for parametertuning
I also tried using the extra tree classifier for feature selection but that did'nt improve my accuracy

# KAGGLE
Took part in a kaggle competition https://www.kaggle.com/c/new-york-city-taxi-fare-prediction
new york taxi fair challenge part of kaggle playground
Currently at 290 out of 610 teams
Leaderboard name -:RohanLeekha
Used XGboost and baesian optimization for model training and optimization
and added newfeatures like havesine distance to cater for spherical shape of earth
removed outliers (morethan 3 passengers not possible and taxi riding beyond the said latitude and longitude of ney york)
Ways to improve 
extract date time from the key column

# Analytics Vidhya
Took part in a weekend machine learning hackathon conducted by IIT-BHU Enigma. By using model stacking/ ensembling finished 70 out of 904 registered participants.
Due to time constraint and less computational power parameters for xgboost and lightgbm were not optimized.
Also more time could have been spent on data-visualization
PVT leaderboard -:https://datahack.analyticsvidhya.com/contest/enigma-codefest-machine-learning/pvt_lb
username -: rohan7797

Using Random Forest and feature engineering I managed to get a rank of 243 out of 3500+ registered participants in Genpact 48hr Hackathon
Homepage -: https://datahack.analyticsvidhya.com/contest/genpact-machine-learning-hackathon/
Username -: rohan7797

Used FastAI and used an ensemble of 20 different variations of ResNet, DenseNet to finish 21st out of 10,000 registered users on the janatahack on computer vision
Leaderboard - : https://datahack.analyticsvidhya.com/contest/janatahack-computer-vision-hackathon/#LeaderBoard
username -: rohan7797
# Machine Hack
https://www.machinehack.com/course/predict-the-flight-ticket-price-hackathon/leaderboard
Ranked 70th out of 2500+ users
Predict the flight ticket cost using NLP and Predictive Analytics

Churn Prediction Hackathon
Was not able to participate as I submitted my solution after the time limit. But results on test data show a significant better result over existing participants.

Message Polarity Predicition
Finished 75 out of 300 participants. Main focus was on feature engineering and model stacking.

Weekly hackathon no 8
https://www.machinehack.com/course/e-commerce-price-prediction-weekend-hackathon-8/leaderboard
Finished 20th out of 445 users.
used tf-idf and hand made feature engineering

