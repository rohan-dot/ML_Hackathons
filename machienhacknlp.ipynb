{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.decomposition import LatentDirichletAllocation\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom keras.preprocessing import sequence, text\nfrom keras.layers import Input, Embedding\n\nfrom nltk import word_tokenize\nfrom nltk.corpus import stopwords\nfrom textblob import TextBlob\n\nimport datetime as dt\nimport pandas as pd\nimport numpy as np\nimport warnings\nimport string\n\n# stop_words = []\nstop_words = list(set(stopwords.words('english')))\nwarnings.filterwarnings('ignore')\npunctuation = string.punctuation\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":66,"outputs":[{"output_type":"stream","text":"/kaggle/input/ecommerce/Train.csv\n/kaggle/input/ecommerce/Sample_Submission.xlsx\n/kaggle/input/ecommerce/Test.csv\n","name":"stdout"}]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np # linear algebra\nimport pandas as pd \nfrom xgboost import XGBRegressor\nfrom lightgbm import LGBMRegressor\nfrom catboost import CatBoostRegressor\nimport time\nfrom sklearn.model_selection import *\nfrom sklearn.metrics import *\nfrom sklearn.linear_model import *\nfrom wordcloud import WordCloud, STOPWORDS\nfrom sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\nfrom nltk.tokenize import TreebankWordTokenizer\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport re\nimport numpy as np","execution_count":67,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.read_csv(r'/kaggle/input/ecommerce/Train.csv')\ntest = pd.read_csv(r'/kaggle/input/ecommerce/Test.csv')","execution_count":68,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":69,"outputs":[{"output_type":"execute_result","execution_count":69,"data":{"text/plain":"  Product Product_Brand             Item_Category     Subcategory_1  \\\n0  P-2610         B-659        bags wallets belts              bags   \n1  P-2453        B-3078                  clothing  women s clothing   \n2  P-6802        B-1810  home decor festive needs        showpieces   \n3  P-4452        B-3078  beauty and personal care          eye care   \n4  P-8454        B-3078                  clothing    men s clothing   \n\n       Subcategory_2  Item_Rating        Date  Selling_Price  \n0          hand bags          4.3    2/3/2017          291.0  \n1       western wear          3.1    7/1/2015          897.0  \n2             ethnic          3.5   1/12/2019          792.0  \n3  h2o plus eye care          4.0  12/12/2014          837.0  \n4           t shirts          4.3  12/12/2013          470.0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Product</th>\n      <th>Product_Brand</th>\n      <th>Item_Category</th>\n      <th>Subcategory_1</th>\n      <th>Subcategory_2</th>\n      <th>Item_Rating</th>\n      <th>Date</th>\n      <th>Selling_Price</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>P-2610</td>\n      <td>B-659</td>\n      <td>bags wallets belts</td>\n      <td>bags</td>\n      <td>hand bags</td>\n      <td>4.3</td>\n      <td>2/3/2017</td>\n      <td>291.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>P-2453</td>\n      <td>B-3078</td>\n      <td>clothing</td>\n      <td>women s clothing</td>\n      <td>western wear</td>\n      <td>3.1</td>\n      <td>7/1/2015</td>\n      <td>897.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>P-6802</td>\n      <td>B-1810</td>\n      <td>home decor festive needs</td>\n      <td>showpieces</td>\n      <td>ethnic</td>\n      <td>3.5</td>\n      <td>1/12/2019</td>\n      <td>792.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>P-4452</td>\n      <td>B-3078</td>\n      <td>beauty and personal care</td>\n      <td>eye care</td>\n      <td>h2o plus eye care</td>\n      <td>4.0</td>\n      <td>12/12/2014</td>\n      <td>837.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>P-8454</td>\n      <td>B-3078</td>\n      <td>clothing</td>\n      <td>men s clothing</td>\n      <td>t shirts</td>\n      <td>4.3</td>\n      <td>12/12/2013</td>\n      <td>470.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.drop(['Product'],inplace=True,axis=1)","execution_count":70,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.drop(['Product'],inplace=True,axis=1)","execution_count":71,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['Item_Rating'] = train['Item_Rating'].round()\ntest['Item_Rating'] = test['Item_Rating'].round()","execution_count":72,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from fastai import *\n#from fastai.structured import add_datepart","execution_count":73,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def add_datepart(df, fldname, drop=True):\n    fld = df[fldname]\n    if not np.issubdtype(fld.dtype, np.datetime64):\n        df[fldname] = fld = pd.to_datetime(fld, infer_datetime_format=True)\n    targ_pre = re.sub('[Dd]ate$', '', fldname)\n    for n in ('Year', 'Month', 'Week', 'Day', 'Dayofweek', 'Dayofyear',\n            'Is_month_end', 'Is_month_start', 'Is_quarter_end', 'Is_quarter_start', 'Is_year_end', 'Is_year_start'):\n        df[targ_pre+n] = getattr(fld.dt,n.lower())\n    df[targ_pre+'Elapsed'] = fld.astype(np.int64) // 10**9\n    if drop: df.drop(fldname, axis=1, inplace=True)\n        \n        ","execution_count":74,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.concat([train, test], axis=0).reset_index(drop=True)","execution_count":75,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.get_dummies(df, columns = ['Item_Rating','Product_Brand'])","execution_count":76,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#df.drop(['Subcategory_3'],inplace = True, axis=1)","execution_count":77,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Subcategory_3'] = df['Subcategory_1'].str.cat(df['Subcategory_2'],sep=\" \")","execution_count":78,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.drop(['Subcategory_1', 'Subcategory_2'],inplace=True,axis=1)","execution_count":79,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":80,"outputs":[{"output_type":"stream","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 3503 entries, 0 to 3502\nColumns: 1322 entries, Item_Category to Subcategory_3\ndtypes: float64(1), object(3), uint8(1318)\nmemory usage: 4.5+ MB\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"add_datepart(df,'Date')","execution_count":81,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.drop(['Elapsed'],inplace=True , axis=1)","execution_count":82,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#df.drop(['Item_Category'],inplace=True,axis=1)","execution_count":83,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":84,"outputs":[{"output_type":"execute_result","execution_count":84,"data":{"text/plain":"              Item_Category  Selling_Price  Item_Rating_1.0  Item_Rating_2.0  \\\n0        bags wallets belts          291.0                0                0   \n1                  clothing          897.0                0                0   \n2  home decor festive needs          792.0                0                0   \n3  beauty and personal care          837.0                0                0   \n4                  clothing          470.0                0                0   \n\n   Item_Rating_3.0  Item_Rating_4.0  Item_Rating_5.0  Product_Brand_B-1  \\\n0                0                1                0                  0   \n1                1                0                0                  0   \n2                0                1                0                  0   \n3                0                1                0                  0   \n4                0                1                0                  0   \n\n   Product_Brand_B-1000  Product_Brand_B-1004  ...  Week  Day  Dayofweek  \\\n0                     0                     0  ...     5    3          4   \n1                     0                     0  ...    27    1          2   \n2                     0                     0  ...     2   12          5   \n3                     0                     0  ...    50   12          4   \n4                     0                     0  ...    50   12          3   \n\n   Dayofyear  Is_month_end  Is_month_start  Is_quarter_end  Is_quarter_start  \\\n0         34         False           False           False             False   \n1        182         False            True           False              True   \n2         12         False           False           False             False   \n3        346         False           False           False             False   \n4        346         False           False           False             False   \n\n   Is_year_end  Is_year_start  \n0        False          False  \n1        False          False  \n2        False          False  \n3        False          False  \n4        False          False  \n\n[5 rows x 1333 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Item_Category</th>\n      <th>Selling_Price</th>\n      <th>Item_Rating_1.0</th>\n      <th>Item_Rating_2.0</th>\n      <th>Item_Rating_3.0</th>\n      <th>Item_Rating_4.0</th>\n      <th>Item_Rating_5.0</th>\n      <th>Product_Brand_B-1</th>\n      <th>Product_Brand_B-1000</th>\n      <th>Product_Brand_B-1004</th>\n      <th>...</th>\n      <th>Week</th>\n      <th>Day</th>\n      <th>Dayofweek</th>\n      <th>Dayofyear</th>\n      <th>Is_month_end</th>\n      <th>Is_month_start</th>\n      <th>Is_quarter_end</th>\n      <th>Is_quarter_start</th>\n      <th>Is_year_end</th>\n      <th>Is_year_start</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>bags wallets belts</td>\n      <td>291.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>5</td>\n      <td>3</td>\n      <td>4</td>\n      <td>34</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>clothing</td>\n      <td>897.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>27</td>\n      <td>1</td>\n      <td>2</td>\n      <td>182</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>home decor festive needs</td>\n      <td>792.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>2</td>\n      <td>12</td>\n      <td>5</td>\n      <td>12</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>beauty and personal care</td>\n      <td>837.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>50</td>\n      <td>12</td>\n      <td>4</td>\n      <td>346</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>clothing</td>\n      <td>470.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>50</td>\n      <td>12</td>\n      <td>3</td>\n      <td>346</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 1333 columns</p>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"df[\"Item_Category_Len\"] = df['Item_Category'].apply(len)\ndf[\"Subcategory_3_len\"] = df['Subcategory_3'].apply(len)\n","execution_count":85,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['text'] = df.apply(lambda row: ' '.join([str(row['Item_Category']), \n                                           # str(row['project_essay_2']), \n                                           # str(row['project_essay_3']), \n                                            str(row['Subcategory_3'])]), axis=1)\n\n# extract features from text\ndf['char_count'] = df['text'].apply(len)\ndf['word_count'] = df['text'].apply(lambda x: len(x.split()))\ndf['word_density'] = df['char_count'] / (df['word_count']+1)\ndf['punctuation_count'] = df['text'].apply(lambda x: len(\"\".join(_ for _ in x if _ in punctuation))) \ndf['title_word_count'] = df['text'].apply(lambda x: len([wrd for wrd in x.split() if wrd.istitle()]))\ndf['upper_case_word_count'] = df['text'].apply(lambda x: len([wrd for wrd in x.split() if wrd.isupper()]))\ndf['stopword_count'] = df['text'].apply(lambda x: len([wrd for wrd in x.split() if wrd.lower() in stop_words]))","execution_count":86,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pos_dic = {\n    'noun' : ['NN','NNS','NNP','NNPS'],\n    'pron' : ['PRP','PRP$','WP','WP$'],\n    'verb' : ['VB','VBD','VBG','VBN','VBP','VBZ'],\n    'adj' :  ['JJ','JJR','JJS'],\n    'adv' : ['RB','RBR','RBS','WRB']\n}\n\n# function to check and get the part of speech tag count of a words in a given sentence\ndef pos_check(x, flag):\n    cnt = 0\n    try:\n        wiki = TextBlob(x)\n        for tup in wiki.tags:\n            ppo = list(tup)[1]\n            if ppo in pos_dic[flag]:\n                cnt += 1\n    except:\n        pass\n    return cnt\n\ndf['noun_count'] = df['text'].apply(lambda x: pos_check(x, 'noun'))\ndf['verb_count'] = df['text'].apply(lambda x: pos_check(x, 'verb'))\ndf['adj_count'] = df['text'].apply(lambda x: pos_check(x, 'adj'))\ndf['adv_count'] = df['text'].apply(lambda x: pos_check(x, 'adv'))\ndf['pron_count'] = df['text'].apply(lambda x: pos_check(x, 'pron'))","execution_count":87,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['noun_count_Item'] = df['Item_Category'].apply(lambda x: pos_check(x, 'noun'))\ndf['verb_count_Item'] = df['Item_Category'].apply(lambda x: pos_check(x, 'verb'))\ndf['adj_count_Item'] = df['Item_Category'].apply(lambda x: pos_check(x, 'adj'))\ndf['adv_count_Item'] = df['Item_Category'].apply(lambda x: pos_check(x, 'adv'))\ndf['pron_count_Item'] = df['Item_Category'].apply(lambda x: pos_check(x, 'pron'))","execution_count":88,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['noun_count_sub'] = df['Subcategory_3'].apply(lambda x: pos_check(x, 'noun'))\ndf['verb_count_sub'] = df['Subcategory_3'].apply(lambda x: pos_check(x, 'verb'))\ndf['adj_count_sub'] = df['Subcategory_3'].apply(lambda x: pos_check(x, 'adj'))\ndf['adv_count_sub'] = df['Subcategory_3'].apply(lambda x: pos_check(x, 'adv'))\ndf['pron_count_sub'] = df['Subcategory_3'].apply(lambda x: pos_check(x, 'pron'))","execution_count":89,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\ncvec = TfidfVectorizer(max_features=10000, norm = 'l1', lowercase=True, smooth_idf=False, sublinear_tf=False, ngram_range=(1,4), tokenizer=TreebankWordTokenizer().tokenize)\ndf_info = pd.DataFrame(cvec.fit_transform(df['Item_Category']).todense())\ndf_info.columns = ['Item_Category_Top_' + str(c) for c in df_info.columns]\ndf = pd.concat([df, df_info], axis=1)","execution_count":90,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":47,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cvec = TfidfVectorizer(max_features=10000, norm = 'l1', lowercase=True, smooth_idf=False, sublinear_tf=False, ngram_range=(1,4), tokenizer=TreebankWordTokenizer().tokenize)\ndf_info = pd.DataFrame(cvec.fit_transform(df['Subcategory_3']).todense())\ndf_info.columns = ['Subcategory_3_Top_' + str(c) for c in df_info.columns]\ndf = pd.concat([df, df_info], axis=1)","execution_count":91,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.drop(['text'],inplace=True, axis=1)","execution_count":92,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train, test  = df[:train.shape[0]].reset_index(drop=True), df[train.shape[0]:].reset_index(drop=True)","execution_count":93,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":94,"outputs":[{"output_type":"execute_result","execution_count":94,"data":{"text/plain":"              Item_Category  Selling_Price  Item_Rating_1.0  Item_Rating_2.0  \\\n0        bags wallets belts          291.0                0                0   \n1                  clothing          897.0                0                0   \n2  home decor festive needs          792.0                0                0   \n3  beauty and personal care          837.0                0                0   \n4                  clothing          470.0                0                0   \n\n   Item_Rating_3.0  Item_Rating_4.0  Item_Rating_5.0  Product_Brand_B-1  \\\n0                0                1                0                  0   \n1                1                0                0                  0   \n2                0                1                0                  0   \n3                0                1                0                  0   \n4                0                1                0                  0   \n\n   Product_Brand_B-1000  Product_Brand_B-1004  ...  Subcategory_3_Top_3453  \\\n0                     0                     0  ...                     0.0   \n1                     0                     0  ...                     0.0   \n2                     0                     0  ...                     0.0   \n3                     0                     0  ...                     0.0   \n4                     0                     0  ...                     0.0   \n\n   Subcategory_3_Top_3454  Subcategory_3_Top_3455  Subcategory_3_Top_3456  \\\n0                     0.0                     0.0                     0.0   \n1                     0.0                     0.0                     0.0   \n2                     0.0                     0.0                     0.0   \n3                     0.0                     0.0                     0.0   \n4                     0.0                     0.0                     0.0   \n\n   Subcategory_3_Top_3457  Subcategory_3_Top_3458  Subcategory_3_Top_3459  \\\n0                     0.0                     0.0                     0.0   \n1                     0.0                     0.0                     0.0   \n2                     0.0                     0.0                     0.0   \n3                     0.0                     0.0                     0.0   \n4                     0.0                     0.0                     0.0   \n\n   Subcategory_3_Top_3460  Subcategory_3_Top_3461  Subcategory_3_Top_3462  \n0                     0.0                     0.0                     0.0  \n1                     0.0                     0.0                     0.0  \n2                     0.0                     0.0                     0.0  \n3                     0.0                     0.0                     0.0  \n4                     0.0                     0.0                     0.0  \n\n[5 rows x 5958 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Item_Category</th>\n      <th>Selling_Price</th>\n      <th>Item_Rating_1.0</th>\n      <th>Item_Rating_2.0</th>\n      <th>Item_Rating_3.0</th>\n      <th>Item_Rating_4.0</th>\n      <th>Item_Rating_5.0</th>\n      <th>Product_Brand_B-1</th>\n      <th>Product_Brand_B-1000</th>\n      <th>Product_Brand_B-1004</th>\n      <th>...</th>\n      <th>Subcategory_3_Top_3453</th>\n      <th>Subcategory_3_Top_3454</th>\n      <th>Subcategory_3_Top_3455</th>\n      <th>Subcategory_3_Top_3456</th>\n      <th>Subcategory_3_Top_3457</th>\n      <th>Subcategory_3_Top_3458</th>\n      <th>Subcategory_3_Top_3459</th>\n      <th>Subcategory_3_Top_3460</th>\n      <th>Subcategory_3_Top_3461</th>\n      <th>Subcategory_3_Top_3462</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>bags wallets belts</td>\n      <td>291.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>clothing</td>\n      <td>897.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>home decor festive needs</td>\n      <td>792.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>beauty and personal care</td>\n      <td>837.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>clothing</td>\n      <td>470.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 5958 columns</p>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.drop(['Item_Category'],inplace=True, axis=1)","execution_count":95,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.drop(['Subcategory_3'],inplace=True, axis=1)","execution_count":96,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#train.drop(['text'],inplace=True, axis=1)#","execution_count":99,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"TARGET_COL =  'Selling_Price'\nfeatures = [c for c in train.columns if c not in [TARGET_COL]]\ntarget = train[TARGET_COL]","execution_count":100,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#target = np.log1p(target)","execution_count":101,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\ndef rmse(y_true, y_pred):\n    return mean_squared_error(y_true, y_pred) ** 0.5","execution_count":102,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\ntraining_start_time = time.time()\n\nmax_iter = 20\nfolds = StratifiedKFold(n_splits = max_iter)\noofs = np.zeros(len(train))\ntest_preds = np.zeros(len(test))\n\n\nfor fold_, (trn_idx, val_idx) in enumerate(folds.split(train, pd.qcut(target, 10, labels=False, duplicates='drop'))):\n    \n    print(f'\\n---- Fold {fold_} -----\\n')\n    \n    fold_start_time = time.time()\n    \n    X_trn, y_trn = train.iloc[trn_idx][features], target.iloc[trn_idx]\n    X_val, y_val = train.iloc[val_idx][features], target.iloc[val_idx]\n    X_test = test[features]\n    print(X_trn.shape[1], X_val.shape[1])\n    \n    \n    clf = LGBMRegressor(n_estimators=1000, num_leaves=127, max_depth=-1,min_child_samples=4, learning_rate=0.02, colsample_bytree=0.4, reg_alpha=0.5, reg_lambda=2)\n    _ = clf.fit(X_trn, np.log(y_trn), eval_set = [(X_val, np.log(y_val))], verbose=100, early_stopping_rounds=200, eval_metric='rmse')\n\n    oofs[val_idx] = np.exp(clf.predict(X_val))\n    current_test_pred = np.exp(clf.predict(X_test))\n    test_preds += np.exp(clf.predict(X_test))/max_iter\n    \n    \n    print(f'\\n Fold {rmse(np.log(y_val), np.log(oofs[val_idx]))}')\n    \n    fold_end_time = time.time()\n    total_fold_time = int(fold_end_time - fold_start_time)\n    \n    print(f\"\\n->-> Fold ran for {(total_fold_time)//60} minutes {(total_fold_time)%60} seconds\")\n    \n\nprint(f'\\nOOF val score: {rmse(np.log(target), np.log(oofs))}')\ntraining_end_time = time.time()\ntotal_training_time = int(training_end_time - training_start_time)\n\nprint(f'\\n->-> Total training time: {(total_training_time)//60} minutes {(total_training_time)%60} seconds')","execution_count":103,"outputs":[{"output_type":"stream","text":"\n---- Fold 0 -----\n\n5955 5955\nTraining until validation scores don't improve for 200 rounds\n[100]\tvalid_0's rmse: 0.665907\tvalid_0's l2: 0.443432\n[200]\tvalid_0's rmse: 0.652267\tvalid_0's l2: 0.425452\n[300]\tvalid_0's rmse: 0.655045\tvalid_0's l2: 0.429084\nEarly stopping, best iteration is:\n[182]\tvalid_0's rmse: 0.650573\tvalid_0's l2: 0.423245\n\n Fold 0.650572598398268\n\n->-> Fold ran for 0 minutes 6 seconds\n\n---- Fold 1 -----\n\n5955 5955\nTraining until validation scores don't improve for 200 rounds\n[100]\tvalid_0's rmse: 0.697673\tvalid_0's l2: 0.486748\n[200]\tvalid_0's rmse: 0.696907\tvalid_0's l2: 0.48568\n[300]\tvalid_0's rmse: 0.705307\tvalid_0's l2: 0.497457\nEarly stopping, best iteration is:\n[156]\tvalid_0's rmse: 0.693035\tvalid_0's l2: 0.480297\n\n Fold 0.6930346852169773\n\n->-> Fold ran for 0 minutes 6 seconds\n\n---- Fold 2 -----\n\n5955 5955\nTraining until validation scores don't improve for 200 rounds\n[100]\tvalid_0's rmse: 0.834314\tvalid_0's l2: 0.69608\n[200]\tvalid_0's rmse: 0.81371\tvalid_0's l2: 0.662123\n[300]\tvalid_0's rmse: 0.815941\tvalid_0's l2: 0.66576\nEarly stopping, best iteration is:\n[196]\tvalid_0's rmse: 0.812936\tvalid_0's l2: 0.660865\n\n Fold 0.8129361792396786\n\n->-> Fold ran for 0 minutes 6 seconds\n\n---- Fold 3 -----\n\n5955 5955\nTraining until validation scores don't improve for 200 rounds\n[100]\tvalid_0's rmse: 0.664748\tvalid_0's l2: 0.44189\n[200]\tvalid_0's rmse: 0.660952\tvalid_0's l2: 0.436858\n[300]\tvalid_0's rmse: 0.671204\tvalid_0's l2: 0.450515\nEarly stopping, best iteration is:\n[155]\tvalid_0's rmse: 0.656384\tvalid_0's l2: 0.43084\n\n Fold 0.6563836529964083\n\n->-> Fold ran for 0 minutes 6 seconds\n\n---- Fold 4 -----\n\n5955 5955\nTraining until validation scores don't improve for 200 rounds\n[100]\tvalid_0's rmse: 0.640409\tvalid_0's l2: 0.410124\n[200]\tvalid_0's rmse: 0.611574\tvalid_0's l2: 0.374022\n[300]\tvalid_0's rmse: 0.608905\tvalid_0's l2: 0.370765\n[400]\tvalid_0's rmse: 0.611629\tvalid_0's l2: 0.37409\nEarly stopping, best iteration is:\n[242]\tvalid_0's rmse: 0.608756\tvalid_0's l2: 0.370584\n\n Fold 0.6087560292370798\n\n->-> Fold ran for 0 minutes 6 seconds\n\n---- Fold 5 -----\n\n5955 5955\nTraining until validation scores don't improve for 200 rounds\n[100]\tvalid_0's rmse: 0.641813\tvalid_0's l2: 0.411924\n[200]\tvalid_0's rmse: 0.630263\tvalid_0's l2: 0.397231\n[300]\tvalid_0's rmse: 0.636176\tvalid_0's l2: 0.40472\nEarly stopping, best iteration is:\n[188]\tvalid_0's rmse: 0.628657\tvalid_0's l2: 0.39521\n\n Fold 0.6286571535438323\n\n->-> Fold ran for 0 minutes 6 seconds\n\n---- Fold 6 -----\n\n5955 5955\nTraining until validation scores don't improve for 200 rounds\n[100]\tvalid_0's rmse: 0.632658\tvalid_0's l2: 0.400256\n[200]\tvalid_0's rmse: 0.637942\tvalid_0's l2: 0.406969\n[300]\tvalid_0's rmse: 0.647181\tvalid_0's l2: 0.418844\nEarly stopping, best iteration is:\n[128]\tvalid_0's rmse: 0.629488\tvalid_0's l2: 0.396255\n\n Fold 0.6294875621218131\n\n->-> Fold ran for 0 minutes 6 seconds\n\n---- Fold 7 -----\n\n5955 5955\nTraining until validation scores don't improve for 200 rounds\n[100]\tvalid_0's rmse: 0.617644\tvalid_0's l2: 0.381484\n[200]\tvalid_0's rmse: 0.595146\tvalid_0's l2: 0.354199\n[300]\tvalid_0's rmse: 0.601721\tvalid_0's l2: 0.362068\nEarly stopping, best iteration is:\n[183]\tvalid_0's rmse: 0.593195\tvalid_0's l2: 0.35188\n\n Fold 0.5931948585687863\n\n->-> Fold ran for 0 minutes 6 seconds\n\n---- Fold 8 -----\n\n5955 5955\nTraining until validation scores don't improve for 200 rounds\n[100]\tvalid_0's rmse: 0.614322\tvalid_0's l2: 0.377391\n[200]\tvalid_0's rmse: 0.608692\tvalid_0's l2: 0.370506\n[300]\tvalid_0's rmse: 0.61302\tvalid_0's l2: 0.375793\nEarly stopping, best iteration is:\n[172]\tvalid_0's rmse: 0.605392\tvalid_0's l2: 0.3665\n\n Fold 0.6053923455875467\n\n->-> Fold ran for 0 minutes 7 seconds\n\n---- Fold 9 -----\n\n5955 5955\nTraining until validation scores don't improve for 200 rounds\n[100]\tvalid_0's rmse: 0.827113\tvalid_0's l2: 0.684116\n[200]\tvalid_0's rmse: 0.803376\tvalid_0's l2: 0.645413\n[300]\tvalid_0's rmse: 0.78614\tvalid_0's l2: 0.618016\n[400]\tvalid_0's rmse: 0.780457\tvalid_0's l2: 0.609113\n[500]\tvalid_0's rmse: 0.77688\tvalid_0's l2: 0.603543\n[600]\tvalid_0's rmse: 0.774676\tvalid_0's l2: 0.600122\n[700]\tvalid_0's rmse: 0.774011\tvalid_0's l2: 0.599093\n[800]\tvalid_0's rmse: 0.774839\tvalid_0's l2: 0.600376\n[900]\tvalid_0's rmse: 0.774015\tvalid_0's l2: 0.599099\n[1000]\tvalid_0's rmse: 0.773818\tvalid_0's l2: 0.598795\nDid not meet early stopping. Best iteration is:\n[968]\tvalid_0's rmse: 0.773478\tvalid_0's l2: 0.598269\n\n Fold 0.7734783425007384\n\n->-> Fold ran for 0 minutes 9 seconds\n\n---- Fold 10 -----\n\n5955 5955\nTraining until validation scores don't improve for 200 rounds\n[100]\tvalid_0's rmse: 0.648164\tvalid_0's l2: 0.420117\n[200]\tvalid_0's rmse: 0.635031\tvalid_0's l2: 0.403264\n[300]\tvalid_0's rmse: 0.6353\tvalid_0's l2: 0.403606\n[400]\tvalid_0's rmse: 0.641544\tvalid_0's l2: 0.411578\nEarly stopping, best iteration is:\n[219]\tvalid_0's rmse: 0.634526\tvalid_0's l2: 0.402623\n\n Fold 0.6345261104713096\n\n->-> Fold ran for 0 minutes 6 seconds\n\n---- Fold 11 -----\n\n5955 5955\nTraining until validation scores don't improve for 200 rounds\n[100]\tvalid_0's rmse: 0.611325\tvalid_0's l2: 0.373718\n[200]\tvalid_0's rmse: 0.572826\tvalid_0's l2: 0.32813\n[300]\tvalid_0's rmse: 0.568919\tvalid_0's l2: 0.323669\n[400]\tvalid_0's rmse: 0.571327\tvalid_0's l2: 0.326415\nEarly stopping, best iteration is:\n[283]\tvalid_0's rmse: 0.568265\tvalid_0's l2: 0.322925\n\n Fold 0.5682650625412168\n\n->-> Fold ran for 0 minutes 6 seconds\n\n---- Fold 12 -----\n\n5955 5955\nTraining until validation scores don't improve for 200 rounds\n[100]\tvalid_0's rmse: 0.605957\tvalid_0's l2: 0.367184\n[200]\tvalid_0's rmse: 0.592608\tvalid_0's l2: 0.351184\n[300]\tvalid_0's rmse: 0.601779\tvalid_0's l2: 0.362138\nEarly stopping, best iteration is:\n[176]\tvalid_0's rmse: 0.590826\tvalid_0's l2: 0.349075\n\n Fold 0.5908258832104344\n\n->-> Fold ran for 0 minutes 6 seconds\n\n---- Fold 13 -----\n\n5955 5955\nTraining until validation scores don't improve for 200 rounds\n[100]\tvalid_0's rmse: 0.690839\tvalid_0's l2: 0.477259\n[200]\tvalid_0's rmse: 0.691263\tvalid_0's l2: 0.477845\n[300]\tvalid_0's rmse: 0.705119\tvalid_0's l2: 0.497193\nEarly stopping, best iteration is:\n[146]\tvalid_0's rmse: 0.680953\tvalid_0's l2: 0.463697\n\n Fold 0.6809533465417459\n\n->-> Fold ran for 0 minutes 6 seconds\n\n---- Fold 14 -----\n\n5955 5955\nTraining until validation scores don't improve for 200 rounds\n[100]\tvalid_0's rmse: 0.684094\tvalid_0's l2: 0.467985\n[200]\tvalid_0's rmse: 0.668073\tvalid_0's l2: 0.446322\n[300]\tvalid_0's rmse: 0.669051\tvalid_0's l2: 0.447629\n[400]\tvalid_0's rmse: 0.669827\tvalid_0's l2: 0.448669\nEarly stopping, best iteration is:\n[247]\tvalid_0's rmse: 0.66727\tvalid_0's l2: 0.445249\n\n Fold 0.6672700310447576\n\n->-> Fold ran for 0 minutes 6 seconds\n\n---- Fold 15 -----\n\n5955 5955\nTraining until validation scores don't improve for 200 rounds\n[100]\tvalid_0's rmse: 0.661008\tvalid_0's l2: 0.436932\n[200]\tvalid_0's rmse: 0.614789\tvalid_0's l2: 0.377966\n[300]\tvalid_0's rmse: 0.608138\tvalid_0's l2: 0.369832\n[400]\tvalid_0's rmse: 0.603596\tvalid_0's l2: 0.364328\n[500]\tvalid_0's rmse: 0.602984\tvalid_0's l2: 0.363589\n[600]\tvalid_0's rmse: 0.604368\tvalid_0's l2: 0.365261\nEarly stopping, best iteration is:\n[478]\tvalid_0's rmse: 0.602462\tvalid_0's l2: 0.36296\n\n Fold 0.6024618468768369\n\n->-> Fold ran for 0 minutes 7 seconds\n\n---- Fold 16 -----\n\n5955 5955\nTraining until validation scores don't improve for 200 rounds\n[100]\tvalid_0's rmse: 0.665726\tvalid_0's l2: 0.443191\n[200]\tvalid_0's rmse: 0.661815\tvalid_0's l2: 0.437999\n[300]\tvalid_0's rmse: 0.663516\tvalid_0's l2: 0.440253\nEarly stopping, best iteration is:\n[135]\tvalid_0's rmse: 0.660491\tvalid_0's l2: 0.436249\n\n Fold 0.6604912578264073\n\n->-> Fold ran for 0 minutes 6 seconds\n\n---- Fold 17 -----\n\n5955 5955\nTraining until validation scores don't improve for 200 rounds\n[100]\tvalid_0's rmse: 0.764337\tvalid_0's l2: 0.584211\n[200]\tvalid_0's rmse: 0.751935\tvalid_0's l2: 0.565406\n[300]\tvalid_0's rmse: 0.749329\tvalid_0's l2: 0.561494\n[400]\tvalid_0's rmse: 0.746838\tvalid_0's l2: 0.557767\n[500]\tvalid_0's rmse: 0.746938\tvalid_0's l2: 0.557917\n[600]\tvalid_0's rmse: 0.74898\tvalid_0's l2: 0.560971\nEarly stopping, best iteration is:\n[433]\tvalid_0's rmse: 0.74628\tvalid_0's l2: 0.556934\n","name":"stdout"},{"output_type":"stream","text":"\n Fold 0.7462804363094185\n\n->-> Fold ran for 0 minutes 8 seconds\n\n---- Fold 18 -----\n\n5955 5955\nTraining until validation scores don't improve for 200 rounds\n[100]\tvalid_0's rmse: 0.751693\tvalid_0's l2: 0.565043\n[200]\tvalid_0's rmse: 0.741048\tvalid_0's l2: 0.549152\n[300]\tvalid_0's rmse: 0.737615\tvalid_0's l2: 0.544076\n[400]\tvalid_0's rmse: 0.735241\tvalid_0's l2: 0.540579\n[500]\tvalid_0's rmse: 0.73523\tvalid_0's l2: 0.540564\nEarly stopping, best iteration is:\n[359]\tvalid_0's rmse: 0.734319\tvalid_0's l2: 0.539225\n\n Fold 0.734319379296395\n\n->-> Fold ran for 0 minutes 7 seconds\n\n---- Fold 19 -----\n\n5955 5955\nTraining until validation scores don't improve for 200 rounds\n[100]\tvalid_0's rmse: 0.595437\tvalid_0's l2: 0.354546\n[200]\tvalid_0's rmse: 0.563969\tvalid_0's l2: 0.318061\n[300]\tvalid_0's rmse: 0.568355\tvalid_0's l2: 0.323028\n[400]\tvalid_0's rmse: 0.574146\tvalid_0's l2: 0.329644\nEarly stopping, best iteration is:\n[216]\tvalid_0's rmse: 0.563012\tvalid_0's l2: 0.316982\n\n Fold 0.5630119642764325\n\n->-> Fold ran for 0 minutes 6 seconds\n\nOOF val score: 0.6584012926203036\n\n->-> Total training time: 2 minutes 16 seconds\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(f'\\nOOF val score: {rmse(np.log(target), np.log(oofs))}')","execution_count":104,"outputs":[{"output_type":"stream","text":"\nOOF val score: 0.6584012926203036\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"vp0, tp0 = oofs, test_preds","execution_count":105,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"training_start_time = time.time()\n\nmax_iter = 10\nfolds = StratifiedKFold(n_splits = max_iter)\noofs = np.zeros(len(train))\ntest_preds = np.zeros(len(test))\n\n\nfor fold_, (trn_idx, val_idx) in enumerate(folds.split(train, pd.qcut(target, 10, labels=False, duplicates='drop'))):\n    \n    print(f'\\n---- Fold {fold_} -----\\n')\n    \n    fold_start_time = time.time()\n    \n    X_trn, y_trn = train.iloc[trn_idx][features], target.iloc[trn_idx]\n    X_val, y_val = train.iloc[val_idx][features], target.iloc[val_idx]\n    X_test = test[features]\n    print(X_trn.shape[1], X_val.shape[1])\n    \n\n    clf = XGBRegressor(n_estimators=3000, max_depth=12, learning_rate=0.05, colsample_bytree=0.9,subsample=1)\n    _ = clf.fit(X_trn, np.log(y_trn), eval_set = [(X_val, np.log(y_val))], verbose=100, early_stopping_rounds=200, eval_metric='rmse')\n    \n\n    oofs[val_idx] = np.exp(clf.predict(X_val))\n    current_test_pred = np.exp(clf.predict(X_test))\n    test_preds += np.exp(clf.predict(X_test))/max_iter\n    \n    \n    print(f'\\n Fold {rmse(np.log(y_val), np.log(oofs[val_idx]))}')\n    \n    fold_end_time = time.time()\n    total_fold_time = int(fold_end_time - fold_start_time)\n    \n    print(f\"\\n->-> Fold ran for {(total_fold_time)//60} minutes {(total_fold_time)%60} seconds\")\n    \n\nprint(f'\\nOOF val score: {rmse(np.log(target), np.log(oofs))}')\ntraining_end_time = time.time()\ntotal_training_time = int(training_end_time - training_start_time)\n\nprint(f'\\n->-> Total training time: {(total_training_time)//60} minutes {(total_training_time)%60} seconds')\n","execution_count":106,"outputs":[{"output_type":"stream","text":"\n---- Fold 0 -----\n\n5955 5955\n[0]\tvalidation_0-rmse:6.01196\nWill train until validation_0-rmse hasn't improved in 200 rounds.\n[100]\tvalidation_0-rmse:0.64306\n[200]\tvalidation_0-rmse:0.63759\n[300]\tvalidation_0-rmse:0.63309\n[400]\tvalidation_0-rmse:0.63062\n[500]\tvalidation_0-rmse:0.63040\n[600]\tvalidation_0-rmse:0.63011\n[700]\tvalidation_0-rmse:0.62899\n[800]\tvalidation_0-rmse:0.62917\n[900]\tvalidation_0-rmse:0.62960\nStopping. Best iteration:\n[703]\tvalidation_0-rmse:0.62876\n\n\n Fold 0.6287636039275231\n\n->-> Fold ran for 5 minutes 38 seconds\n\n---- Fold 1 -----\n\n5955 5955\n[0]\tvalidation_0-rmse:5.95588\nWill train until validation_0-rmse hasn't improved in 200 rounds.\n[100]\tvalidation_0-rmse:0.75758\n[200]\tvalidation_0-rmse:0.74993\n[300]\tvalidation_0-rmse:0.74711\n[400]\tvalidation_0-rmse:0.74774\n[500]\tvalidation_0-rmse:0.74497\n[600]\tvalidation_0-rmse:0.74332\n[700]\tvalidation_0-rmse:0.74283\n[800]\tvalidation_0-rmse:0.74247\n[900]\tvalidation_0-rmse:0.74169\n[1000]\tvalidation_0-rmse:0.74185\n[1100]\tvalidation_0-rmse:0.74177\n[1200]\tvalidation_0-rmse:0.74160\n[1300]\tvalidation_0-rmse:0.74119\n[1400]\tvalidation_0-rmse:0.74177\nStopping. Best iteration:\n[1292]\tvalidation_0-rmse:0.74115\n\n\n Fold 0.7411459040214731\n\n->-> Fold ran for 9 minutes 14 seconds\n\n---- Fold 2 -----\n\n5955 5955\n[0]\tvalidation_0-rmse:5.94460\nWill train until validation_0-rmse hasn't improved in 200 rounds.\n[100]\tvalidation_0-rmse:0.60971\n[200]\tvalidation_0-rmse:0.59734\n[300]\tvalidation_0-rmse:0.59479\n[400]\tvalidation_0-rmse:0.59081\n[500]\tvalidation_0-rmse:0.58889\n[600]\tvalidation_0-rmse:0.58627\n[700]\tvalidation_0-rmse:0.58600\n[800]\tvalidation_0-rmse:0.58657\nStopping. Best iteration:\n[657]\tvalidation_0-rmse:0.58545\n\n\n Fold 0.5854485073521576\n\n->-> Fold ran for 5 minutes 29 seconds\n\n---- Fold 3 -----\n\n5955 5955\n[0]\tvalidation_0-rmse:5.92138\nWill train until validation_0-rmse hasn't improved in 200 rounds.\n[100]\tvalidation_0-rmse:0.60029\n[200]\tvalidation_0-rmse:0.58940\n[300]\tvalidation_0-rmse:0.58747\n[400]\tvalidation_0-rmse:0.58595\n[500]\tvalidation_0-rmse:0.58742\nStopping. Best iteration:\n[397]\tvalidation_0-rmse:0.58592\n\n\n Fold 0.5859180012679122\n\n->-> Fold ran for 3 minutes 46 seconds\n\n---- Fold 4 -----\n\n5955 5955\n[0]\tvalidation_0-rmse:5.92192\nWill train until validation_0-rmse hasn't improved in 200 rounds.\n[100]\tvalidation_0-rmse:0.72503\n[200]\tvalidation_0-rmse:0.71633\n[300]\tvalidation_0-rmse:0.71548\n[400]\tvalidation_0-rmse:0.71287\n[500]\tvalidation_0-rmse:0.71403\n[600]\tvalidation_0-rmse:0.71429\nStopping. Best iteration:\n[413]\tvalidation_0-rmse:0.71279\n\n\n Fold 0.7127936661498877\n\n->-> Fold ran for 4 minutes 0 seconds\n\n---- Fold 5 -----\n\n5955 5955\n[0]\tvalidation_0-rmse:5.93959\nWill train until validation_0-rmse hasn't improved in 200 rounds.\n[100]\tvalidation_0-rmse:0.59152\n[200]\tvalidation_0-rmse:0.58259\n[300]\tvalidation_0-rmse:0.57548\n[400]\tvalidation_0-rmse:0.57423\n[500]\tvalidation_0-rmse:0.57295\n[600]\tvalidation_0-rmse:0.57039\n[700]\tvalidation_0-rmse:0.56868\n[800]\tvalidation_0-rmse:0.56813\n[900]\tvalidation_0-rmse:0.56814\n[1000]\tvalidation_0-rmse:0.56806\n[1100]\tvalidation_0-rmse:0.56871\nStopping. Best iteration:\n[953]\tvalidation_0-rmse:0.56756\n\n\n Fold 0.5675630360168503\n\n->-> Fold ran for 7 minutes 9 seconds\n\n---- Fold 6 -----\n\n5955 5955\n[0]\tvalidation_0-rmse:5.92667\nWill train until validation_0-rmse hasn't improved in 200 rounds.\n[100]\tvalidation_0-rmse:0.64205\n[200]\tvalidation_0-rmse:0.62777\n[300]\tvalidation_0-rmse:0.62338\n[400]\tvalidation_0-rmse:0.62469\nStopping. Best iteration:\n[296]\tvalidation_0-rmse:0.62286\n\n\n Fold 0.6228555507395649\n\n->-> Fold ran for 3 minutes 10 seconds\n\n---- Fold 7 -----\n\n5955 5955\n[0]\tvalidation_0-rmse:5.97939\nWill train until validation_0-rmse hasn't improved in 200 rounds.\n[100]\tvalidation_0-rmse:0.62764\n[200]\tvalidation_0-rmse:0.60677\n[300]\tvalidation_0-rmse:0.59806\n[400]\tvalidation_0-rmse:0.59265\n[500]\tvalidation_0-rmse:0.59135\n[600]\tvalidation_0-rmse:0.59010\n[700]\tvalidation_0-rmse:0.58950\n[800]\tvalidation_0-rmse:0.58909\n[900]\tvalidation_0-rmse:0.58882\n[1000]\tvalidation_0-rmse:0.58809\n[1100]\tvalidation_0-rmse:0.58871\nStopping. Best iteration:\n[987]\tvalidation_0-rmse:0.58795\n\n\n Fold 0.5879468488063089\n\n->-> Fold ran for 7 minutes 23 seconds\n\n---- Fold 8 -----\n\n5955 5955\n[0]\tvalidation_0-rmse:5.94600\nWill train until validation_0-rmse hasn't improved in 200 rounds.\n[100]\tvalidation_0-rmse:0.70501\n[200]\tvalidation_0-rmse:0.69187\n[300]\tvalidation_0-rmse:0.68786\n[400]\tvalidation_0-rmse:0.68648\n[500]\tvalidation_0-rmse:0.68646\n[600]\tvalidation_0-rmse:0.68780\nStopping. Best iteration:\n[412]\tvalidation_0-rmse:0.68617\n\n\n Fold 0.686170625387809\n\n->-> Fold ran for 3 minutes 58 seconds\n\n---- Fold 9 -----\n\n5955 5955\n[0]\tvalidation_0-rmse:6.00318\nWill train until validation_0-rmse hasn't improved in 200 rounds.\n[100]\tvalidation_0-rmse:0.62637\n[200]\tvalidation_0-rmse:0.61728\n[300]\tvalidation_0-rmse:0.61763\n[400]\tvalidation_0-rmse:0.61852\n[500]\tvalidation_0-rmse:0.61998\nStopping. Best iteration:\n[345]\tvalidation_0-rmse:0.61604\n\n\n Fold 0.6160397228936152\n\n->-> Fold ran for 3 minutes 27 seconds\n\nOOF val score: 0.6360355564967527\n\n->-> Total training time: 53 minutes 18 seconds\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"vp1, tp1 = oofs, test_preds","execution_count":107,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"training_start_time = time.time()\n\nmax_iter = 10\nfolds = StratifiedKFold(n_splits = max_iter)\noofs = np.zeros(len(train))\ntest_preds = np.zeros(len(test))\n\n\nfor fold_, (trn_idx, val_idx) in enumerate(folds.split(train, pd.qcut(target, 10, labels=False, duplicates='drop'))):\n    \n    print(f'\\n---- Fold {fold_} -----\\n')\n    \n    fold_start_time = time.time()\n    \n    X_trn, y_trn = train.iloc[trn_idx][features], target.iloc[trn_idx]\n    X_val, y_val = train.iloc[val_idx][features], target.iloc[val_idx]\n    X_test = test[features]\n    print(X_trn.shape[1], X_val.shape[1])\n    \n    \n    \n    clf = CatBoostRegressor(n_estimators=2000, learning_rate=0.05, max_depth=10, rsm=0.5)\n    _ = clf.fit(X_trn, np.log(y_trn), eval_set = [(X_val, np.log(y_val))], verbose=100, early_stopping_rounds=200)\n\n    oofs[val_idx] = np.exp(clf.predict(X_val))\n    current_test_pred = np.exp(clf.predict(X_test))\n    test_preds += np.exp(clf.predict(X_test))/max_iter\n    \n    \n    \n    print(f'\\n Fold {rmse(np.log(y_val), np.log(oofs[val_idx]))}')\n    \n    fold_end_time = time.time()\n    total_fold_time = int(fold_end_time - fold_start_time)\n    \n    print(f\"\\n->-> Fold ran for {(total_fold_time)//60} minutes {(total_fold_time)%60} seconds\")\n    \n\nprint(f'\\nOOF val score: {rmse(np.log(target), np.log(oofs))}')\ntraining_end_time = time.time()\ntotal_training_time = int(training_end_time - training_start_time)\n\nprint(f'\\n->-> Total training time: {(total_training_time)//60} minutes {(total_training_time)%60} seconds')\n","execution_count":131,"outputs":[{"output_type":"stream","text":"\n---- Fold 0 -----\n\n5955 5955\n0:\tlearn: 1.1431241\ttest: 1.2117389\tbest: 1.2117389 (0)\ttotal: 167ms\tremaining: 5m 34s\n100:\tlearn: 0.6718573\ttest: 0.6941477\tbest: 0.6941477 (100)\ttotal: 7.46s\tremaining: 2m 20s\n200:\tlearn: 0.6070368\ttest: 0.6777321\tbest: 0.6777321 (200)\ttotal: 14.6s\tremaining: 2m 10s\n300:\tlearn: 0.5436266\ttest: 0.6574582\tbest: 0.6574582 (300)\ttotal: 21.9s\tremaining: 2m 3s\n400:\tlearn: 0.5037531\ttest: 0.6477544\tbest: 0.6477544 (400)\ttotal: 29.3s\tremaining: 1m 56s\n500:\tlearn: 0.4751833\ttest: 0.6385161\tbest: 0.6385161 (500)\ttotal: 36.7s\tremaining: 1m 49s\n600:\tlearn: 0.4504002\ttest: 0.6340693\tbest: 0.6340693 (600)\ttotal: 44s\tremaining: 1m 42s\n700:\tlearn: 0.4304151\ttest: 0.6306256\tbest: 0.6306256 (700)\ttotal: 51.3s\tremaining: 1m 34s\n800:\tlearn: 0.4119985\ttest: 0.6277611\tbest: 0.6277550 (795)\ttotal: 59.1s\tremaining: 1m 28s\n900:\tlearn: 0.3946195\ttest: 0.6256645\tbest: 0.6254259 (898)\ttotal: 1m 6s\tremaining: 1m 21s\n1000:\tlearn: 0.3785758\ttest: 0.6237321\tbest: 0.6235846 (986)\ttotal: 1m 13s\tremaining: 1m 13s\n1100:\tlearn: 0.3678586\ttest: 0.6220342\tbest: 0.6220285 (1097)\ttotal: 1m 21s\tremaining: 1m 6s\n1200:\tlearn: 0.3540074\ttest: 0.6215199\tbest: 0.6212031 (1193)\ttotal: 1m 28s\tremaining: 58.9s\n1300:\tlearn: 0.3442279\ttest: 0.6211790\tbest: 0.6211778 (1299)\ttotal: 1m 35s\tremaining: 51.6s\n1400:\tlearn: 0.3333112\ttest: 0.6216197\tbest: 0.6208006 (1309)\ttotal: 1m 43s\tremaining: 44.2s\n1500:\tlearn: 0.3221648\ttest: 0.6211324\tbest: 0.6208006 (1309)\ttotal: 1m 50s\tremaining: 36.7s\nStopped by overfitting detector  (200 iterations wait)\n\nbestTest = 0.620800601\nbestIteration = 1309\n\nShrink model to first 1310 iterations.\n\n Fold 0.6208006056549144\n\n->-> Fold ran for 1 minutes 54 seconds\n\n---- Fold 1 -----\n\n5955 5955\n0:\tlearn: 1.1473203\ttest: 1.1599297\tbest: 1.1599297 (0)\ttotal: 91.4ms\tremaining: 3m 2s\n100:\tlearn: 0.6568074\ttest: 0.8004387\tbest: 0.8003027 (99)\ttotal: 7.28s\tremaining: 2m 16s\n200:\tlearn: 0.5924401\ttest: 0.7758622\tbest: 0.7758622 (200)\ttotal: 14.5s\tremaining: 2m 10s\n300:\tlearn: 0.5318872\ttest: 0.7635350\tbest: 0.7635350 (300)\ttotal: 21.7s\tremaining: 2m 2s\n400:\tlearn: 0.4950090\ttest: 0.7573405\tbest: 0.7573405 (400)\ttotal: 28.7s\tremaining: 1m 54s\n500:\tlearn: 0.4666263\ttest: 0.7518933\tbest: 0.7518933 (500)\ttotal: 35.8s\tremaining: 1m 46s\n600:\tlearn: 0.4413173\ttest: 0.7493006\tbest: 0.7491394 (599)\ttotal: 42.9s\tremaining: 1m 39s\n700:\tlearn: 0.4182911\ttest: 0.7458346\tbest: 0.7454266 (693)\ttotal: 49.9s\tremaining: 1m 32s\n800:\tlearn: 0.4002163\ttest: 0.7451930\tbest: 0.7448492 (789)\ttotal: 57s\tremaining: 1m 25s\n900:\tlearn: 0.3858586\ttest: 0.7455687\tbest: 0.7448492 (789)\ttotal: 1m 4s\tremaining: 1m 18s\n1000:\tlearn: 0.3719865\ttest: 0.7445432\tbest: 0.7444530 (988)\ttotal: 1m 11s\tremaining: 1m 11s\n1100:\tlearn: 0.3593522\ttest: 0.7447992\tbest: 0.7444530 (988)\ttotal: 1m 18s\tremaining: 1m 4s\n1200:\tlearn: 0.3467908\ttest: 0.7448947\tbest: 0.7444237 (1117)\ttotal: 1m 25s\tremaining: 57.1s\n1300:\tlearn: 0.3368360\ttest: 0.7437282\tbest: 0.7437282 (1300)\ttotal: 1m 32s\tremaining: 49.9s\n1400:\tlearn: 0.3266534\ttest: 0.7438225\tbest: 0.7431469 (1328)\ttotal: 1m 40s\tremaining: 42.8s\n1500:\tlearn: 0.3154565\ttest: 0.7436455\tbest: 0.7431469 (1328)\ttotal: 1m 47s\tremaining: 35.7s\nStopped by overfitting detector  (200 iterations wait)\n\nbestTest = 0.7431469464\nbestIteration = 1328\n\nShrink model to first 1329 iterations.\n\n Fold 0.7431469342418425\n\n->-> Fold ran for 1 minutes 52 seconds\n\n---- Fold 2 -----\n\n5955 5955\n0:\tlearn: 1.1459882\ttest: 1.1562932\tbest: 1.1562932 (0)\ttotal: 117ms\tremaining: 3m 53s\n100:\tlearn: 0.6782644\ttest: 0.6777781\tbest: 0.6772771 (94)\ttotal: 7.22s\tremaining: 2m 15s\n200:\tlearn: 0.6107443\ttest: 0.6555462\tbest: 0.6555462 (200)\ttotal: 14.9s\tremaining: 2m 13s\n300:\tlearn: 0.5457953\ttest: 0.6338106\tbest: 0.6338106 (300)\ttotal: 22.4s\tremaining: 2m 6s\n400:\tlearn: 0.5071503\ttest: 0.6276444\tbest: 0.6276178 (399)\ttotal: 29.9s\tremaining: 1m 59s\n500:\tlearn: 0.4771797\ttest: 0.6245542\tbest: 0.6243294 (497)\ttotal: 37.3s\tremaining: 1m 51s\n600:\tlearn: 0.4517593\ttest: 0.6205995\tbest: 0.6205995 (600)\ttotal: 44.7s\tremaining: 1m 44s\n700:\tlearn: 0.4315575\ttest: 0.6168671\tbest: 0.6168671 (700)\ttotal: 52.1s\tremaining: 1m 36s\n800:\tlearn: 0.4092869\ttest: 0.6132225\tbest: 0.6132225 (800)\ttotal: 59.4s\tremaining: 1m 28s\n900:\tlearn: 0.3936986\ttest: 0.6107223\tbest: 0.6107026 (899)\ttotal: 1m 7s\tremaining: 1m 21s\n1000:\tlearn: 0.3784259\ttest: 0.6072388\tbest: 0.6072388 (1000)\ttotal: 1m 14s\tremaining: 1m 14s\n1100:\tlearn: 0.3659926\ttest: 0.6037377\tbest: 0.6037376 (1098)\ttotal: 1m 22s\tremaining: 1m 7s\n1200:\tlearn: 0.3558462\ttest: 0.6029920\tbest: 0.6028128 (1150)\ttotal: 1m 29s\tremaining: 59.7s\n1300:\tlearn: 0.3457304\ttest: 0.6014196\tbest: 0.6012394 (1295)\ttotal: 1m 37s\tremaining: 52.2s\n1400:\tlearn: 0.3326872\ttest: 0.6011788\tbest: 0.6005326 (1337)\ttotal: 1m 44s\tremaining: 44.7s\n1500:\tlearn: 0.3224463\ttest: 0.6006898\tbest: 0.6005326 (1337)\ttotal: 1m 52s\tremaining: 37.2s\nStopped by overfitting detector  (200 iterations wait)\n\nbestTest = 0.6005326036\nbestIteration = 1337\n\nShrink model to first 1338 iterations.\n\n Fold 0.6005326075000122\n\n->-> Fold ran for 1 minutes 57 seconds\n\n---- Fold 3 -----\n\n5955 5955\n0:\tlearn: 1.1581883\ttest: 1.0665300\tbest: 1.0665300 (0)\ttotal: 49.8ms\tremaining: 1m 39s\n100:\tlearn: 0.6820557\ttest: 0.6434156\tbest: 0.6434156 (100)\ttotal: 6.92s\tremaining: 2m 10s\n200:\tlearn: 0.6146080\ttest: 0.6213932\tbest: 0.6213932 (200)\ttotal: 14.5s\tremaining: 2m 9s\n300:\tlearn: 0.5436681\ttest: 0.5966527\tbest: 0.5966503 (299)\ttotal: 21.9s\tremaining: 2m 3s\n400:\tlearn: 0.5027428\ttest: 0.5865931\tbest: 0.5864643 (388)\ttotal: 29s\tremaining: 1m 55s\n500:\tlearn: 0.4743643\ttest: 0.5786879\tbest: 0.5786870 (499)\ttotal: 36.1s\tremaining: 1m 48s\n600:\tlearn: 0.4494674\ttest: 0.5769670\tbest: 0.5768723 (598)\ttotal: 43.2s\tremaining: 1m 40s\n700:\tlearn: 0.4290487\ttest: 0.5731269\tbest: 0.5731059 (697)\ttotal: 50.3s\tremaining: 1m 33s\n800:\tlearn: 0.4094913\ttest: 0.5702036\tbest: 0.5700543 (798)\ttotal: 57.5s\tremaining: 1m 26s\n900:\tlearn: 0.3923972\ttest: 0.5690264\tbest: 0.5690257 (899)\ttotal: 1m 4s\tremaining: 1m 18s\n1000:\tlearn: 0.3780604\ttest: 0.5680250\tbest: 0.5679069 (990)\ttotal: 1m 12s\tremaining: 1m 11s\n1100:\tlearn: 0.3632886\ttest: 0.5679410\tbest: 0.5674431 (1093)\ttotal: 1m 19s\tremaining: 1m 4s\n1200:\tlearn: 0.3512348\ttest: 0.5672354\tbest: 0.5670656 (1190)\ttotal: 1m 26s\tremaining: 57.5s\n1300:\tlearn: 0.3374024\ttest: 0.5679862\tbest: 0.5670656 (1190)\ttotal: 1m 33s\tremaining: 50.3s\nStopped by overfitting detector  (200 iterations wait)\n\nbestTest = 0.5670655561\nbestIteration = 1190\n\nShrink model to first 1191 iterations.\n\n Fold 0.5670655550959465\n\n->-> Fold ran for 1 minutes 42 seconds\n\n---- Fold 4 -----\n\n5955 5955\n0:\tlearn: 1.1526676\ttest: 1.1169503\tbest: 1.1169503 (0)\ttotal: 85.3ms\tremaining: 2m 50s\n100:\tlearn: 0.6653373\ttest: 0.7778343\tbest: 0.7778343 (100)\ttotal: 7.39s\tremaining: 2m 18s\n200:\tlearn: 0.5998665\ttest: 0.7515138\tbest: 0.7515138 (200)\ttotal: 14.8s\tremaining: 2m 12s\n300:\tlearn: 0.5369828\ttest: 0.7282995\tbest: 0.7282995 (300)\ttotal: 22.1s\tremaining: 2m 4s\n400:\tlearn: 0.5001516\ttest: 0.7161330\tbest: 0.7160545 (395)\ttotal: 29.7s\tremaining: 1m 58s\n500:\tlearn: 0.4730089\ttest: 0.7098560\tbest: 0.7098296 (499)\ttotal: 37.3s\tremaining: 1m 51s\n600:\tlearn: 0.4485594\ttest: 0.7045088\tbest: 0.7044906 (591)\ttotal: 44.8s\tremaining: 1m 44s\n700:\tlearn: 0.4266327\ttest: 0.7006616\tbest: 0.7006015 (698)\ttotal: 52.1s\tremaining: 1m 36s\n800:\tlearn: 0.4081243\ttest: 0.6995981\tbest: 0.6995877 (796)\ttotal: 59.5s\tremaining: 1m 29s\n900:\tlearn: 0.3878671\ttest: 0.6977173\tbest: 0.6972820 (894)\ttotal: 1m 6s\tremaining: 1m 21s\n1000:\tlearn: 0.3727671\ttest: 0.6958227\tbest: 0.6958227 (1000)\ttotal: 1m 14s\tremaining: 1m 14s\n1100:\tlearn: 0.3598722\ttest: 0.6950172\tbest: 0.6950172 (1100)\ttotal: 1m 21s\tremaining: 1m 6s\n1200:\tlearn: 0.3484332\ttest: 0.6946493\tbest: 0.6946493 (1200)\ttotal: 1m 29s\tremaining: 59.4s\n1300:\tlearn: 0.3359000\ttest: 0.6940568\tbest: 0.6934812 (1269)\ttotal: 1m 36s\tremaining: 52s\n1400:\tlearn: 0.3249791\ttest: 0.6928379\tbest: 0.6927667 (1392)\ttotal: 1m 44s\tremaining: 44.6s\n1500:\tlearn: 0.3151539\ttest: 0.6922394\tbest: 0.6921839 (1491)\ttotal: 1m 51s\tremaining: 37.1s\n1600:\tlearn: 0.3047246\ttest: 0.6921140\tbest: 0.6918954 (1534)\ttotal: 1m 59s\tremaining: 29.7s\n1700:\tlearn: 0.2943433\ttest: 0.6932076\tbest: 0.6918954 (1534)\ttotal: 2m 6s\tremaining: 22.2s\n","name":"stdout"},{"output_type":"stream","text":"Stopped by overfitting detector  (200 iterations wait)\n\nbestTest = 0.6918954272\nbestIteration = 1534\n\nShrink model to first 1535 iterations.\n\n Fold 0.6918954372459585\n\n->-> Fold ran for 2 minutes 11 seconds\n\n---- Fold 5 -----\n\n5955 5955\n0:\tlearn: 1.1498982\ttest: 1.1455924\tbest: 1.1455924 (0)\ttotal: 87.9ms\tremaining: 2m 55s\n100:\tlearn: 0.6820876\ttest: 0.6649821\tbest: 0.6649760 (99)\ttotal: 7.59s\tremaining: 2m 22s\n200:\tlearn: 0.6140598\ttest: 0.6338910\tbest: 0.6338910 (200)\ttotal: 15.2s\tremaining: 2m 15s\n300:\tlearn: 0.5479430\ttest: 0.6082189\tbest: 0.6082188 (299)\ttotal: 23.1s\tremaining: 2m 10s\n400:\tlearn: 0.5073639\ttest: 0.5989463\tbest: 0.5989463 (400)\ttotal: 30.6s\tremaining: 2m 2s\n500:\tlearn: 0.4795625\ttest: 0.5953051\tbest: 0.5952368 (498)\ttotal: 38.2s\tremaining: 1m 54s\n600:\tlearn: 0.4560825\ttest: 0.5888149\tbest: 0.5888149 (600)\ttotal: 45.7s\tremaining: 1m 46s\n700:\tlearn: 0.4349785\ttest: 0.5880721\tbest: 0.5880676 (699)\ttotal: 53.2s\tremaining: 1m 38s\n800:\tlearn: 0.4143724\ttest: 0.5849458\tbest: 0.5849360 (794)\ttotal: 1m\tremaining: 1m 30s\n900:\tlearn: 0.3991748\ttest: 0.5821884\tbest: 0.5821884 (900)\ttotal: 1m 8s\tremaining: 1m 23s\n1000:\tlearn: 0.3852666\ttest: 0.5805717\tbest: 0.5805717 (1000)\ttotal: 1m 16s\tremaining: 1m 16s\n1100:\tlearn: 0.3718783\ttest: 0.5788316\tbest: 0.5786767 (1089)\ttotal: 1m 23s\tremaining: 1m 8s\n1200:\tlearn: 0.3592212\ttest: 0.5779786\tbest: 0.5779786 (1200)\ttotal: 1m 31s\tremaining: 1m\n1300:\tlearn: 0.3447927\ttest: 0.5778123\tbest: 0.5773326 (1229)\ttotal: 1m 38s\tremaining: 53.1s\n1400:\tlearn: 0.3303451\ttest: 0.5768515\tbest: 0.5765050 (1385)\ttotal: 1m 46s\tremaining: 45.5s\n1500:\tlearn: 0.3197734\ttest: 0.5781511\tbest: 0.5765050 (1385)\ttotal: 1m 54s\tremaining: 37.9s\nStopped by overfitting detector  (200 iterations wait)\n\nbestTest = 0.5765050108\nbestIteration = 1385\n\nShrink model to first 1386 iterations.\n\n Fold 0.5765049968158754\n\n->-> Fold ran for 2 minutes 3 seconds\n\n---- Fold 6 -----\n\n5955 5955\n0:\tlearn: 1.1551649\ttest: 1.1010530\tbest: 1.1010530 (0)\ttotal: 83.8ms\tremaining: 2m 47s\n100:\tlearn: 0.6771350\ttest: 0.6848478\tbest: 0.6848478 (100)\ttotal: 7.47s\tremaining: 2m 20s\n200:\tlearn: 0.6090763\ttest: 0.6601442\tbest: 0.6601325 (199)\ttotal: 15.2s\tremaining: 2m 16s\n300:\tlearn: 0.5419076\ttest: 0.6449254\tbest: 0.6449254 (300)\ttotal: 23s\tremaining: 2m 9s\n400:\tlearn: 0.4988134\ttest: 0.6391855\tbest: 0.6391855 (400)\ttotal: 30.4s\tremaining: 2m 1s\n500:\tlearn: 0.4690102\ttest: 0.6336613\tbest: 0.6333630 (498)\ttotal: 37.8s\tremaining: 1m 53s\n600:\tlearn: 0.4400466\ttest: 0.6279235\tbest: 0.6279235 (600)\ttotal: 45.2s\tremaining: 1m 45s\n700:\tlearn: 0.4161251\ttest: 0.6249708\tbest: 0.6249708 (700)\ttotal: 52.9s\tremaining: 1m 38s\n800:\tlearn: 0.3973361\ttest: 0.6216528\tbest: 0.6216201 (783)\ttotal: 1m\tremaining: 1m 30s\n900:\tlearn: 0.3823199\ttest: 0.6195640\tbest: 0.6194487 (897)\ttotal: 1m 7s\tremaining: 1m 22s\n1000:\tlearn: 0.3656590\ttest: 0.6191316\tbest: 0.6190526 (975)\ttotal: 1m 15s\tremaining: 1m 15s\n1100:\tlearn: 0.3533099\ttest: 0.6175790\tbest: 0.6175790 (1100)\ttotal: 1m 23s\tremaining: 1m 8s\n1200:\tlearn: 0.3388272\ttest: 0.6170853\tbest: 0.6170424 (1128)\ttotal: 1m 31s\tremaining: 1m\n1300:\tlearn: 0.3278418\ttest: 0.6180272\tbest: 0.6168794 (1229)\ttotal: 1m 38s\tremaining: 52.9s\n1400:\tlearn: 0.3151301\ttest: 0.6176554\tbest: 0.6168794 (1229)\ttotal: 1m 47s\tremaining: 45.9s\n1500:\tlearn: 0.3078040\ttest: 0.6164160\tbest: 0.6163927 (1499)\ttotal: 1m 57s\tremaining: 39s\n1600:\tlearn: 0.2978076\ttest: 0.6170223\tbest: 0.6160829 (1525)\ttotal: 2m 4s\tremaining: 31.1s\n1700:\tlearn: 0.2884122\ttest: 0.6175065\tbest: 0.6160829 (1525)\ttotal: 2m 12s\tremaining: 23.3s\nStopped by overfitting detector  (200 iterations wait)\n\nbestTest = 0.6160829475\nbestIteration = 1525\n\nShrink model to first 1526 iterations.\n\n Fold 0.6160829360340071\n\n->-> Fold ran for 2 minutes 17 seconds\n\n---- Fold 7 -----\n\n5955 5955\n0:\tlearn: 1.1451482\ttest: 1.1831650\tbest: 1.1831650 (0)\ttotal: 91.7ms\tremaining: 3m 3s\n100:\tlearn: 0.6731461\ttest: 0.7260085\tbest: 0.7260085 (100)\ttotal: 7.3s\tremaining: 2m 17s\n200:\tlearn: 0.6084003\ttest: 0.6859416\tbest: 0.6859416 (200)\ttotal: 14.7s\tremaining: 2m 11s\n300:\tlearn: 0.5451550\ttest: 0.6530156\tbest: 0.6530156 (300)\ttotal: 22.1s\tremaining: 2m 4s\n400:\tlearn: 0.5053262\ttest: 0.6391574\tbest: 0.6391574 (400)\ttotal: 29.4s\tremaining: 1m 57s\n500:\tlearn: 0.4772203\ttest: 0.6273593\tbest: 0.6273568 (499)\ttotal: 36.8s\tremaining: 1m 50s\n600:\tlearn: 0.4526079\ttest: 0.6229521\tbest: 0.6229521 (600)\ttotal: 44.3s\tremaining: 1m 43s\n700:\tlearn: 0.4313096\ttest: 0.6174394\tbest: 0.6174180 (697)\ttotal: 51.6s\tremaining: 1m 35s\n800:\tlearn: 0.4129273\ttest: 0.6126703\tbest: 0.6126458 (794)\ttotal: 59.3s\tremaining: 1m 28s\n900:\tlearn: 0.3963698\ttest: 0.6099892\tbest: 0.6099892 (900)\ttotal: 1m 6s\tremaining: 1m 21s\n1000:\tlearn: 0.3799578\ttest: 0.6084229\tbest: 0.6080868 (983)\ttotal: 1m 14s\tremaining: 1m 14s\n1100:\tlearn: 0.3670532\ttest: 0.6077717\tbest: 0.6070753 (1070)\ttotal: 1m 21s\tremaining: 1m 6s\n1200:\tlearn: 0.3557820\ttest: 0.6059559\tbest: 0.6055707 (1197)\ttotal: 1m 29s\tremaining: 59.3s\n1300:\tlearn: 0.3443472\ttest: 0.6051793\tbest: 0.6049951 (1291)\ttotal: 1m 36s\tremaining: 51.9s\n1400:\tlearn: 0.3336372\ttest: 0.6044545\tbest: 0.6044008 (1398)\ttotal: 1m 43s\tremaining: 44.4s\n1500:\tlearn: 0.3236818\ttest: 0.6040424\tbest: 0.6040424 (1500)\ttotal: 1m 51s\tremaining: 37s\n1600:\tlearn: 0.3138523\ttest: 0.6041167\tbest: 0.6036254 (1522)\ttotal: 1m 58s\tremaining: 29.6s\n1700:\tlearn: 0.3029403\ttest: 0.6026276\tbest: 0.6026276 (1700)\ttotal: 2m 6s\tremaining: 22.2s\n1800:\tlearn: 0.2952629\ttest: 0.6016349\tbest: 0.6016011 (1796)\ttotal: 2m 13s\tremaining: 14.8s\n1900:\tlearn: 0.2866246\ttest: 0.6005535\tbest: 0.6003733 (1880)\ttotal: 2m 21s\tremaining: 7.36s\n1999:\tlearn: 0.2791507\ttest: 0.6000458\tbest: 0.5996799 (1986)\ttotal: 2m 28s\tremaining: 0us\n\nbestTest = 0.5996798843\nbestIteration = 1986\n\nShrink model to first 1987 iterations.\n\n Fold 0.5996798911226269\n\n->-> Fold ran for 2 minutes 31 seconds\n\n---- Fold 8 -----\n\n5955 5955\n0:\tlearn: 1.1495027\ttest: 1.1417498\tbest: 1.1417498 (0)\ttotal: 82.9ms\tremaining: 2m 45s\n100:\tlearn: 0.6687179\ttest: 0.7537103\tbest: 0.7537103 (100)\ttotal: 7.28s\tremaining: 2m 16s\n200:\tlearn: 0.6030061\ttest: 0.7278693\tbest: 0.7278693 (200)\ttotal: 14.6s\tremaining: 2m 10s\n300:\tlearn: 0.5374163\ttest: 0.7109981\tbest: 0.7109981 (300)\ttotal: 22s\tremaining: 2m 4s\n400:\tlearn: 0.4983564\ttest: 0.7019556\tbest: 0.7019556 (400)\ttotal: 30.1s\tremaining: 2m\n500:\tlearn: 0.4692759\ttest: 0.6952960\tbest: 0.6952941 (499)\ttotal: 37.6s\tremaining: 1m 52s\n600:\tlearn: 0.4406618\ttest: 0.6902173\tbest: 0.6901857 (599)\ttotal: 45s\tremaining: 1m 44s\n700:\tlearn: 0.4178792\ttest: 0.6868534\tbest: 0.6868236 (697)\ttotal: 52.4s\tremaining: 1m 37s\n800:\tlearn: 0.4015557\ttest: 0.6827455\tbest: 0.6825488 (799)\ttotal: 59.8s\tremaining: 1m 29s\n900:\tlearn: 0.3864444\ttest: 0.6819776\tbest: 0.6819347 (897)\ttotal: 1m 7s\tremaining: 1m 21s\n1000:\tlearn: 0.3716275\ttest: 0.6800217\tbest: 0.6797598 (995)\ttotal: 1m 14s\tremaining: 1m 14s\n1100:\tlearn: 0.3597289\ttest: 0.6779136\tbest: 0.6779111 (1099)\ttotal: 1m 21s\tremaining: 1m 6s\n1200:\tlearn: 0.3470614\ttest: 0.6767501\tbest: 0.6766305 (1195)\ttotal: 1m 29s\tremaining: 59.7s\n1300:\tlearn: 0.3361317\ttest: 0.6767622\tbest: 0.6759577 (1240)\ttotal: 1m 37s\tremaining: 52.2s\n1400:\tlearn: 0.3262037\ttest: 0.6768048\tbest: 0.6759577 (1240)\ttotal: 1m 44s\tremaining: 44.7s\nStopped by overfitting detector  (200 iterations wait)\n\nbestTest = 0.6759577443\nbestIteration = 1240\n\nShrink model to first 1241 iterations.\n\n Fold 0.6759577690770808\n\n->-> Fold ran for 1 minutes 50 seconds\n\n---- Fold 9 -----\n\n5955 5955\n0:\tlearn: 1.1458515\ttest: 1.2057274\tbest: 1.2057274 (0)\ttotal: 82.5ms\tremaining: 2m 44s\n100:\tlearn: 0.6756923\ttest: 0.7228716\tbest: 0.7228716 (100)\ttotal: 7.55s\tremaining: 2m 22s\n200:\tlearn: 0.6109529\ttest: 0.6893751\tbest: 0.6893751 (200)\ttotal: 15.2s\tremaining: 2m 16s\n300:\tlearn: 0.5422998\ttest: 0.6577282\tbest: 0.6577282 (300)\ttotal: 22.8s\tremaining: 2m 8s\n400:\tlearn: 0.4993336\ttest: 0.6461257\tbest: 0.6461257 (400)\ttotal: 30.4s\tremaining: 2m 1s\n500:\tlearn: 0.4714329\ttest: 0.6412114\tbest: 0.6411941 (498)\ttotal: 38.5s\tremaining: 1m 55s\n600:\tlearn: 0.4463432\ttest: 0.6350733\tbest: 0.6350722 (599)\ttotal: 46.3s\tremaining: 1m 47s\n700:\tlearn: 0.4269174\ttest: 0.6322646\tbest: 0.6322646 (700)\ttotal: 54s\tremaining: 1m 39s\n","name":"stdout"},{"output_type":"stream","text":"800:\tlearn: 0.4077203\ttest: 0.6281755\tbest: 0.6280826 (796)\ttotal: 1m 1s\tremaining: 1m 32s\n900:\tlearn: 0.3910843\ttest: 0.6275537\tbest: 0.6268720 (868)\ttotal: 1m 9s\tremaining: 1m 24s\n1000:\tlearn: 0.3763801\ttest: 0.6262105\tbest: 0.6259799 (990)\ttotal: 1m 16s\tremaining: 1m 16s\n1100:\tlearn: 0.3646014\ttest: 0.6248624\tbest: 0.6248624 (1100)\ttotal: 1m 24s\tremaining: 1m 9s\n1200:\tlearn: 0.3510449\ttest: 0.6237150\tbest: 0.6236621 (1198)\ttotal: 1m 32s\tremaining: 1m 1s\n1300:\tlearn: 0.3380112\ttest: 0.6227617\tbest: 0.6225033 (1294)\ttotal: 1m 40s\tremaining: 54s\n1400:\tlearn: 0.3282210\ttest: 0.6217040\tbest: 0.6214462 (1358)\ttotal: 1m 48s\tremaining: 46.2s\n1500:\tlearn: 0.3173659\ttest: 0.6201399\tbest: 0.6200327 (1488)\ttotal: 1m 55s\tremaining: 38.5s\n1600:\tlearn: 0.3087850\ttest: 0.6207675\tbest: 0.6198276 (1535)\ttotal: 2m 3s\tremaining: 30.7s\n1700:\tlearn: 0.3019848\ttest: 0.6211191\tbest: 0.6198276 (1535)\ttotal: 2m 10s\tremaining: 23s\nStopped by overfitting detector  (200 iterations wait)\n\nbestTest = 0.6198276102\nbestIteration = 1535\n\nShrink model to first 1536 iterations.\n\n Fold 0.6198276244874484\n\n->-> Fold ran for 2 minutes 16 seconds\n\nOOF val score: 0.6333855411809313\n\n->-> Total training time: 20 minutes 37 seconds\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"vp2, tp2 = oofs, test_preds","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"params={'learning_rate': 0.01,\n        'objective':'regression',\n        'metric':'rmse',\n        'num_leaves': 31,\n        'verbose': 1,\n        'bagging_fraction': 0.9,\n        'feature_fraction': 0.9,\n        \"random_state\":42,\n        'max_depth': 5,\n        \"bagging_seed\" : 42,\n        \"verbosity\" : -1,\n        \"bagging_frequency\" : 5,\n        'lambda_l2': 0.5,\n        'lambda_l1': 0.5,\n        'min_child_samples': 36\n       }\n\ncat_param = {\n    'learning_rate' :0.03,\n    'depth' :10,\n    'eval_metric' :'RMSE',\n    'od_type' :'Iter',\n    'metric_period ' : 50,\n    'od_wait' : 20,\n    'seed' : 42\n    \n}\n","execution_count":163,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"training_start_time = time.time()\n\nmax_iter = 10\nfolds = StratifiedKFold(n_splits = max_iter)\noofs = np.zeros(len(train))\ntest_preds = np.zeros(len(test))\n\n\nfor fold_, (trn_idx, val_idx) in enumerate(folds.split(train, pd.qcut(target, 10, labels=False, duplicates='drop'))):\n    \n    print(f'\\n---- Fold {fold_} -----\\n')\n    \n    fold_start_time = time.time()\n    \n    X_trn, y_trn = train.iloc[trn_idx][features], target.iloc[trn_idx]\n    X_val, y_val = train.iloc[val_idx][features], target.iloc[val_idx]\n    X_test = test[features]\n    print(X_trn.shape[1], X_val.shape[1])\n    \n    \n    \n    clf = CatBoostRegressor(iterations=1000,learning_rate=0.03,\n                            depth=10,\n                            eval_metric='RMSE',\n                            random_seed = 42,\n                            bagging_temperature = 0.2,\n                            od_type='Iter',\n                            metric_period = 50,\n                            od_wait=20)\n    _ = clf.fit(X_trn, np.log(y_trn), eval_set = [(X_val, np.log(y_val))], verbose=100, early_stopping_rounds=200)\n\n    oofs[val_idx] = np.exp(clf.predict(X_val))\n    current_test_pred = np.exp(clf.predict(X_test))\n    test_preds += np.exp(clf.predict(X_test))/max_iter\n    \n    \n    \n    print(f'\\n Fold {rmse(np.log(y_val), np.log(oofs[val_idx]))}')\n    \n    fold_end_time = time.time()\n    total_fold_time = int(fold_end_time - fold_start_time)\n    \n    print(f\"\\n->-> Fold ran for {(total_fold_time)//60} minutes {(total_fold_time)%60} seconds\")\n    \n\nprint(f'\\nOOF val score: {rmse(np.log(target), np.log(oofs))}')\ntraining_end_time = time.time()\ntotal_training_time = int(training_end_time - training_start_time)\n\nprint(f'\\n->-> Total training time: {(total_training_time)//60} minutes {(total_training_time)%60} seconds')","execution_count":164,"outputs":[{"output_type":"stream","text":"\n---- Fold 0 -----\n\n5955 5955\n","name":"stdout"},{"output_type":"stream","text":"Warning: Overfitting detector is active, thus evaluation metric is calculated on every iteration. 'metric_period' is ignored for evaluation metric.\n","name":"stderr"},{"output_type":"stream","text":"0:\tlearn: 1.1532072\ttest: 1.2245647\tbest: 1.2245647 (0)\ttotal: 178ms\tremaining: 2m 57s\n100:\tlearn: 0.6981829\ttest: 0.7048990\tbest: 0.7048990 (100)\ttotal: 7.53s\tremaining: 1m 7s\n200:\tlearn: 0.6499107\ttest: 0.6856786\tbest: 0.6856786 (200)\ttotal: 15.2s\tremaining: 1m\n300:\tlearn: 0.6113958\ttest: 0.6755989\tbest: 0.6755621 (299)\ttotal: 22.7s\tremaining: 52.7s\n400:\tlearn: 0.5666016\ttest: 0.6604304\tbest: 0.6602864 (399)\ttotal: 30.1s\tremaining: 45s\n500:\tlearn: 0.5344441\ttest: 0.6517777\tbest: 0.6517777 (499)\ttotal: 37.5s\tremaining: 37.4s\n600:\tlearn: 0.5107962\ttest: 0.6464289\tbest: 0.6464289 (600)\ttotal: 45s\tremaining: 29.9s\n700:\tlearn: 0.4891697\ttest: 0.6419013\tbest: 0.6419013 (700)\ttotal: 52.5s\tremaining: 22.4s\n800:\tlearn: 0.4727435\ttest: 0.6389870\tbest: 0.6389865 (799)\ttotal: 60s\tremaining: 14.9s\n900:\tlearn: 0.4562354\ttest: 0.6366352\tbest: 0.6366152 (896)\ttotal: 1m 7s\tremaining: 7.4s\n999:\tlearn: 0.4395453\ttest: 0.6334917\tbest: 0.6334852 (995)\ttotal: 1m 15s\tremaining: 0us\n\nbestTest = 0.6334852222\nbestIteration = 995\n\nShrink model to first 996 iterations.\n\n Fold 0.6334852257040696\n\n->-> Fold ran for 1 minutes 18 seconds\n\n---- Fold 1 -----\n\n5955 5955\n","name":"stdout"},{"output_type":"stream","text":"Warning: Overfitting detector is active, thus evaluation metric is calculated on every iteration. 'metric_period' is ignored for evaluation metric.\n","name":"stderr"},{"output_type":"stream","text":"0:\tlearn: 1.1603786\ttest: 1.1701198\tbest: 1.1701198 (0)\ttotal: 136ms\tremaining: 2m 16s\n100:\tlearn: 0.6812190\ttest: 0.8043293\tbest: 0.8043293 (100)\ttotal: 7.39s\tremaining: 1m 5s\n200:\tlearn: 0.6357312\ttest: 0.7894028\tbest: 0.7894008 (199)\ttotal: 14.6s\tremaining: 57.9s\n300:\tlearn: 0.6006107\ttest: 0.7802306\tbest: 0.7799465 (298)\ttotal: 21.7s\tremaining: 50.5s\n400:\tlearn: 0.5543528\ttest: 0.7682455\tbest: 0.7682455 (400)\ttotal: 29s\tremaining: 43.3s\n500:\tlearn: 0.5259006\ttest: 0.7628797\tbest: 0.7628797 (500)\ttotal: 36.3s\tremaining: 36.1s\n600:\tlearn: 0.4995845\ttest: 0.7592809\tbest: 0.7592809 (600)\ttotal: 43.5s\tremaining: 28.8s\n700:\tlearn: 0.4783643\ttest: 0.7576904\tbest: 0.7574586 (688)\ttotal: 50.7s\tremaining: 21.6s\n800:\tlearn: 0.4616630\ttest: 0.7552733\tbest: 0.7552073 (798)\ttotal: 58.3s\tremaining: 14.5s\n900:\tlearn: 0.4467011\ttest: 0.7527582\tbest: 0.7527556 (899)\ttotal: 1m 5s\tremaining: 7.22s\n999:\tlearn: 0.4319787\ttest: 0.7515813\tbest: 0.7515813 (999)\ttotal: 1m 12s\tremaining: 0us\n\nbestTest = 0.7515813465\nbestIteration = 999\n\n\n Fold 0.7515813350885293\n\n->-> Fold ran for 1 minutes 15 seconds\n\n---- Fold 2 -----\n\n5955 5955\n","name":"stdout"},{"output_type":"stream","text":"Warning: Overfitting detector is active, thus evaluation metric is calculated on every iteration. 'metric_period' is ignored for evaluation metric.\n","name":"stderr"},{"output_type":"stream","text":"0:\tlearn: 1.1603771\ttest: 1.1724026\tbest: 1.1724026 (0)\ttotal: 91.6ms\tremaining: 1m 31s\n100:\tlearn: 0.7073205\ttest: 0.6956682\tbest: 0.6956682 (100)\ttotal: 7.39s\tremaining: 1m 5s\n200:\tlearn: 0.6560342\ttest: 0.6696439\tbest: 0.6696439 (200)\ttotal: 14.8s\tremaining: 58.8s\n300:\tlearn: 0.6176253\ttest: 0.6569589\tbest: 0.6569589 (300)\ttotal: 22.2s\tremaining: 51.6s\n400:\tlearn: 0.5724228\ttest: 0.6366673\tbest: 0.6366673 (400)\ttotal: 30.1s\tremaining: 44.9s\n500:\tlearn: 0.5375045\ttest: 0.6249845\tbest: 0.6249845 (499)\ttotal: 37.8s\tremaining: 37.7s\n600:\tlearn: 0.5135288\ttest: 0.6194236\tbest: 0.6194236 (600)\ttotal: 45.6s\tremaining: 30.3s\n700:\tlearn: 0.4939005\ttest: 0.6154974\tbest: 0.6152752 (686)\ttotal: 53.3s\tremaining: 22.7s\n800:\tlearn: 0.4769831\ttest: 0.6121541\tbest: 0.6121491 (797)\ttotal: 1m\tremaining: 15.1s\n900:\tlearn: 0.4585539\ttest: 0.6101323\tbest: 0.6099817 (874)\ttotal: 1m 8s\tremaining: 7.52s\n999:\tlearn: 0.4456612\ttest: 0.6086198\tbest: 0.6086198 (999)\ttotal: 1m 15s\tremaining: 0us\n\nbestTest = 0.6086197671\nbestIteration = 999\n\n\n Fold 0.6086197718210786\n\n->-> Fold ran for 1 minutes 18 seconds\n\n---- Fold 3 -----\n\n5955 5955\n","name":"stdout"},{"output_type":"stream","text":"Warning: Overfitting detector is active, thus evaluation metric is calculated on every iteration. 'metric_period' is ignored for evaluation metric.\n","name":"stderr"},{"output_type":"stream","text":"0:\tlearn: 1.1692505\ttest: 1.0795587\tbest: 1.0795587 (0)\ttotal: 86.9ms\tremaining: 1m 26s\n100:\tlearn: 0.7071453\ttest: 0.6556991\tbest: 0.6556991 (100)\ttotal: 7.1s\tremaining: 1m 3s\n200:\tlearn: 0.6613467\ttest: 0.6347263\tbest: 0.6347196 (199)\ttotal: 14.1s\tremaining: 56s\n300:\tlearn: 0.6231144\ttest: 0.6230667\tbest: 0.6230548 (294)\ttotal: 21.4s\tremaining: 49.8s\n400:\tlearn: 0.5763845\ttest: 0.6066716\tbest: 0.6066716 (400)\ttotal: 28.8s\tremaining: 43s\n500:\tlearn: 0.5385792\ttest: 0.5942566\tbest: 0.5941524 (499)\ttotal: 36s\tremaining: 35.9s\n600:\tlearn: 0.5132530\ttest: 0.5893477\tbest: 0.5893053 (598)\ttotal: 43.2s\tremaining: 28.7s\n700:\tlearn: 0.4918145\ttest: 0.5845717\tbest: 0.5845717 (700)\ttotal: 50.6s\tremaining: 21.6s\n800:\tlearn: 0.4722867\ttest: 0.5825561\tbest: 0.5825561 (800)\ttotal: 57.8s\tremaining: 14.4s\n900:\tlearn: 0.4557347\ttest: 0.5798349\tbest: 0.5797660 (894)\ttotal: 1m 4s\tremaining: 7.14s\n999:\tlearn: 0.4421496\ttest: 0.5761956\tbest: 0.5761956 (999)\ttotal: 1m 12s\tremaining: 0us\n\nbestTest = 0.5761955534\nbestIteration = 999\n\n\n Fold 0.5761955543059131\n\n->-> Fold ran for 1 minutes 14 seconds\n\n---- Fold 4 -----\n\n5955 5955\n","name":"stdout"},{"output_type":"stream","text":"Warning: Overfitting detector is active, thus evaluation metric is calculated on every iteration. 'metric_period' is ignored for evaluation metric.\n","name":"stderr"},{"output_type":"stream","text":"0:\tlearn: 1.1640815\ttest: 1.1243020\tbest: 1.1243020 (0)\ttotal: 77.7ms\tremaining: 1m 17s\n100:\tlearn: 0.6940447\ttest: 0.7923039\tbest: 0.7923039 (100)\ttotal: 7.83s\tremaining: 1m 9s\n200:\tlearn: 0.6432271\ttest: 0.7669887\tbest: 0.7669887 (200)\ttotal: 15.4s\tremaining: 1m 1s\n300:\tlearn: 0.6028761\ttest: 0.7510119\tbest: 0.7509955 (298)\ttotal: 22.8s\tremaining: 53s\n400:\tlearn: 0.5612707\ttest: 0.7370386\tbest: 0.7370386 (400)\ttotal: 30.3s\tremaining: 45.3s\n500:\tlearn: 0.5257350\ttest: 0.7244287\tbest: 0.7244287 (500)\ttotal: 37.9s\tremaining: 37.7s\n600:\tlearn: 0.5011289\ttest: 0.7177119\tbest: 0.7176698 (598)\ttotal: 45.3s\tremaining: 30.1s\n700:\tlearn: 0.4797178\ttest: 0.7132121\tbest: 0.7132121 (700)\ttotal: 52.8s\tremaining: 22.5s\n800:\tlearn: 0.4650006\ttest: 0.7107264\tbest: 0.7106682 (799)\ttotal: 1m\tremaining: 15s\n900:\tlearn: 0.4518273\ttest: 0.7086084\tbest: 0.7086084 (900)\ttotal: 1m 8s\tremaining: 7.48s\n999:\tlearn: 0.4363969\ttest: 0.7055043\tbest: 0.7054954 (995)\ttotal: 1m 15s\tremaining: 0us\n\nbestTest = 0.705495395\nbestIteration = 995\n\nShrink model to first 996 iterations.\n\n Fold 0.7054954059855598\n\n->-> Fold ran for 1 minutes 18 seconds\n\n---- Fold 5 -----\n\n5955 5955\n","name":"stdout"},{"output_type":"stream","text":"Warning: Overfitting detector is active, thus evaluation metric is calculated on every iteration. 'metric_period' is ignored for evaluation metric.\n","name":"stderr"},{"output_type":"stream","text":"0:\tlearn: 1.1624534\ttest: 1.1583127\tbest: 1.1583127 (0)\ttotal: 79ms\tremaining: 1m 18s\n100:\tlearn: 0.7081151\ttest: 0.6830739\tbest: 0.6830739 (100)\ttotal: 7.72s\tremaining: 1m 8s\n200:\tlearn: 0.6587743\ttest: 0.6511875\tbest: 0.6511855 (199)\ttotal: 15.2s\tremaining: 1m\n300:\tlearn: 0.6185448\ttest: 0.6360657\tbest: 0.6360656 (299)\ttotal: 22.7s\tremaining: 52.8s\n400:\tlearn: 0.5748330\ttest: 0.6171524\tbest: 0.6171342 (399)\ttotal: 30.5s\tremaining: 45.5s\n500:\tlearn: 0.5429023\ttest: 0.6095721\tbest: 0.6095291 (497)\ttotal: 38.2s\tremaining: 38s\n600:\tlearn: 0.5184824\ttest: 0.6045352\tbest: 0.6044892 (599)\ttotal: 46.9s\tremaining: 31.1s\n700:\tlearn: 0.4942749\ttest: 0.6004455\tbest: 0.6004455 (700)\ttotal: 54.7s\tremaining: 23.3s\n800:\tlearn: 0.4773211\ttest: 0.5971956\tbest: 0.5970617 (788)\ttotal: 1m 2s\tremaining: 15.5s\n900:\tlearn: 0.4629633\ttest: 0.5957711\tbest: 0.5955526 (893)\ttotal: 1m 10s\tremaining: 7.71s\n999:\tlearn: 0.4435222\ttest: 0.5932919\tbest: 0.5932502 (998)\ttotal: 1m 17s\tremaining: 0us\n\nbestTest = 0.5932501574\nbestIteration = 998\n\nShrink model to first 999 iterations.\n\n Fold 0.5932501430069427\n\n->-> Fold ran for 1 minutes 20 seconds\n\n---- Fold 6 -----\n\n5955 5955\n","name":"stdout"},{"output_type":"stream","text":"Warning: Overfitting detector is active, thus evaluation metric is calculated on every iteration. 'metric_period' is ignored for evaluation metric.\n","name":"stderr"},{"output_type":"stream","text":"0:\tlearn: 1.1662493\ttest: 1.1107594\tbest: 1.1107594 (0)\ttotal: 88.7ms\tremaining: 1m 28s\n100:\tlearn: 0.7038441\ttest: 0.7073685\tbest: 0.7073685 (100)\ttotal: 7.54s\tremaining: 1m 7s\n200:\tlearn: 0.6554613\ttest: 0.6805015\tbest: 0.6805015 (200)\ttotal: 15s\tremaining: 59.7s\n300:\tlearn: 0.6180388\ttest: 0.6687314\tbest: 0.6687265 (299)\ttotal: 22.5s\tremaining: 52.4s\n400:\tlearn: 0.5709573\ttest: 0.6524010\tbest: 0.6524010 (400)\ttotal: 30.4s\tremaining: 45.4s\n500:\tlearn: 0.5363810\ttest: 0.6416067\tbest: 0.6414992 (496)\ttotal: 38.1s\tremaining: 37.9s\n600:\tlearn: 0.5117616\ttest: 0.6364772\tbest: 0.6364772 (600)\ttotal: 46s\tremaining: 30.5s\n700:\tlearn: 0.4873498\ttest: 0.6321122\tbest: 0.6320377 (693)\ttotal: 53.6s\tremaining: 22.9s\n800:\tlearn: 0.4658722\ttest: 0.6269160\tbest: 0.6269160 (800)\ttotal: 1m 1s\tremaining: 15.2s\n900:\tlearn: 0.4488774\ttest: 0.6234153\tbest: 0.6232752 (895)\ttotal: 1m 8s\tremaining: 7.55s\n999:\tlearn: 0.4319148\ttest: 0.6208258\tbest: 0.6207376 (997)\ttotal: 1m 16s\tremaining: 0us\n\nbestTest = 0.6207376467\nbestIteration = 997\n\nShrink model to first 998 iterations.\n\n Fold 0.6207376380606903\n\n->-> Fold ran for 1 minutes 18 seconds\n\n---- Fold 7 -----\n\n5955 5955\n","name":"stdout"},{"output_type":"stream","text":"Warning: Overfitting detector is active, thus evaluation metric is calculated on every iteration. 'metric_period' is ignored for evaluation metric.\n","name":"stderr"},{"output_type":"stream","text":"0:\tlearn: 1.1582036\ttest: 1.1981059\tbest: 1.1981059 (0)\ttotal: 78.8ms\tremaining: 1m 18s\n100:\tlearn: 0.6982653\ttest: 0.7491703\tbest: 0.7491703 (100)\ttotal: 7.61s\tremaining: 1m 7s\n200:\tlearn: 0.6529128\ttest: 0.7251137\tbest: 0.7250008 (195)\ttotal: 15s\tremaining: 59.5s\n300:\tlearn: 0.6138638\ttest: 0.7053022\tbest: 0.7052229 (299)\ttotal: 22.3s\tremaining: 51.8s\n400:\tlearn: 0.5669717\ttest: 0.6761477\tbest: 0.6761477 (400)\ttotal: 29.7s\tremaining: 44.3s\n500:\tlearn: 0.5340554\ttest: 0.6600141\tbest: 0.6600141 (500)\ttotal: 37.1s\tremaining: 36.9s\n600:\tlearn: 0.5092773\ttest: 0.6513892\tbest: 0.6513892 (600)\ttotal: 44.4s\tremaining: 29.5s\n700:\tlearn: 0.4885678\ttest: 0.6418048\tbest: 0.6418048 (700)\ttotal: 51.7s\tremaining: 22s\n800:\tlearn: 0.4701006\ttest: 0.6351977\tbest: 0.6351388 (796)\ttotal: 59s\tremaining: 14.7s\n900:\tlearn: 0.4542211\ttest: 0.6313106\tbest: 0.6313106 (900)\ttotal: 1m 6s\tremaining: 7.32s\n999:\tlearn: 0.4409248\ttest: 0.6277841\tbest: 0.6277291 (998)\ttotal: 1m 14s\tremaining: 0us\n\nbestTest = 0.6277291084\nbestIteration = 998\n\nShrink model to first 999 iterations.\n\n Fold 0.6277291120977199\n\n->-> Fold ran for 1 minutes 16 seconds\n\n---- Fold 8 -----\n\n5955 5955\n","name":"stdout"},{"output_type":"stream","text":"Warning: Overfitting detector is active, thus evaluation metric is calculated on every iteration. 'metric_period' is ignored for evaluation metric.\n","name":"stderr"},{"output_type":"stream","text":"0:\tlearn: 1.1610555\ttest: 1.1538346\tbest: 1.1538346 (0)\ttotal: 82.8ms\tremaining: 1m 22s\n100:\tlearn: 0.6924359\ttest: 0.7666085\tbest: 0.7666085 (100)\ttotal: 7.35s\tremaining: 1m 5s\n200:\tlearn: 0.6450632\ttest: 0.7461265\tbest: 0.7461265 (200)\ttotal: 14.6s\tremaining: 58s\n300:\tlearn: 0.6052784\ttest: 0.7322666\tbest: 0.7321301 (297)\ttotal: 22.1s\tremaining: 51.3s\n400:\tlearn: 0.5577096\ttest: 0.7189315\tbest: 0.7189315 (400)\ttotal: 29.4s\tremaining: 44s\n500:\tlearn: 0.5224764\ttest: 0.7098483\tbest: 0.7098483 (500)\ttotal: 36.8s\tremaining: 36.6s\n600:\tlearn: 0.4982747\ttest: 0.7044236\tbest: 0.7044236 (600)\ttotal: 44.3s\tremaining: 29.4s\n700:\tlearn: 0.4779387\ttest: 0.7004244\tbest: 0.7004244 (700)\ttotal: 52s\tremaining: 22.2s\n800:\tlearn: 0.4587045\ttest: 0.6958106\tbest: 0.6955533 (792)\ttotal: 59.7s\tremaining: 14.8s\n900:\tlearn: 0.4431286\ttest: 0.6922153\tbest: 0.6921845 (878)\ttotal: 1m 7s\tremaining: 7.37s\n999:\tlearn: 0.4289944\ttest: 0.6905555\tbest: 0.6903433 (969)\ttotal: 1m 14s\tremaining: 0us\n\nbestTest = 0.6903433242\nbestIteration = 969\n\nShrink model to first 970 iterations.\n\n Fold 0.6903433468985352\n\n->-> Fold ran for 1 minutes 16 seconds\n\n---- Fold 9 -----\n\n5955 5955\n","name":"stdout"},{"output_type":"stream","text":"Warning: Overfitting detector is active, thus evaluation metric is calculated on every iteration. 'metric_period' is ignored for evaluation metric.\n","name":"stderr"},{"output_type":"stream","text":"0:\tlearn: 1.1550354\ttest: 1.2146964\tbest: 1.2146964 (0)\ttotal: 82.8ms\tremaining: 1m 22s\n100:\tlearn: 0.7002268\ttest: 0.7284320\tbest: 0.7284320 (100)\ttotal: 7.68s\tremaining: 1m 8s\n200:\tlearn: 0.6506626\ttest: 0.7036550\tbest: 0.7036550 (200)\ttotal: 15.4s\tremaining: 1m 1s\n300:\tlearn: 0.6139504\ttest: 0.6885615\tbest: 0.6885615 (300)\ttotal: 22.9s\tremaining: 53.3s\n400:\tlearn: 0.5648602\ttest: 0.6645954\tbest: 0.6645954 (400)\ttotal: 30.5s\tremaining: 45.6s\n500:\tlearn: 0.5293623\ttest: 0.6525662\tbest: 0.6525662 (500)\ttotal: 38.6s\tremaining: 38.4s\n600:\tlearn: 0.5045527\ttest: 0.6462824\tbest: 0.6462824 (600)\ttotal: 46.5s\tremaining: 30.9s\n700:\tlearn: 0.4835746\ttest: 0.6402145\tbest: 0.6402145 (700)\ttotal: 54.2s\tremaining: 23.1s\n800:\tlearn: 0.4659509\ttest: 0.6362535\tbest: 0.6362526 (799)\ttotal: 1m 1s\tremaining: 15.3s\n900:\tlearn: 0.4512502\ttest: 0.6342233\tbest: 0.6340136 (893)\ttotal: 1m 9s\tremaining: 7.63s\n999:\tlearn: 0.4372222\ttest: 0.6312821\tbest: 0.6312821 (999)\ttotal: 1m 17s\tremaining: 0us\n\nbestTest = 0.6312820704\nbestIteration = 999\n\n\n Fold 0.6312820862571982\n\n->-> Fold ran for 1 minutes 19 seconds\n\nOOF val score: 0.6460072589748772\n\n->-> Total training time: 12 minutes 57 seconds\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"vp3, tp3 = oofs, test_preds","execution_count":165,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\ntraining_start_time = time.time()\n\nmax_iter = 20\nfolds = StratifiedKFold(n_splits = max_iter)\noofs = np.zeros(len(train))\ntest_preds = np.zeros(len(test))\n\n\nfor fold_, (trn_idx, val_idx) in enumerate(folds.split(train, pd.qcut(target, 10, labels=False, duplicates='drop'))):\n    \n    print(f'\\n---- Fold {fold_} -----\\n')\n    \n    fold_start_time = time.time()\n    \n    X_trn, y_trn = train.iloc[trn_idx][features], target.iloc[trn_idx]\n    X_val, y_val = train.iloc[val_idx][features], target.iloc[val_idx]\n    X_test = test[features]\n    print(X_trn.shape[1], X_val.shape[1])\n    \n    \n    #clf = LGBMRegressor(n_estimators=1000, num_leaves=127, max_depth=-1,min_child_samples=4, learning_rate=0.02, colsample_bytree=0.4, reg_alpha=0.5, reg_lambda=2)\n    clf = LGBMRegressor(**params,n_estimators=1100)\n    _ = clf.fit(X_trn, np.log(y_trn), eval_set = [(X_val, np.log(y_val))], verbose=100, early_stopping_rounds=200, eval_metric='rmse')\n\n    oofs[val_idx] = np.exp(clf.predict(X_val))\n    current_test_pred = np.exp(clf.predict(X_test))\n    test_preds += np.exp(clf.predict(X_test))/max_iter\n    \n    \n    print(f'\\n Fold {rmse(np.log(y_val), np.log(oofs[val_idx]))}')\n    \n    fold_end_time = time.time()\n    total_fold_time = int(fold_end_time - fold_start_time)\n    \n    print(f\"\\n->-> Fold ran for {(total_fold_time)//60} minutes {(total_fold_time)%60} seconds\")\n    \n\nprint(f'\\nOOF val score: {rmse(np.log(target), np.log(oofs))}')\ntraining_end_time = time.time()\ntotal_training_time = int(training_end_time - training_start_time)\n\nprint(f'\\n->-> Total training time: {(total_training_time)//60} minutes {(total_training_time)%60} seconds')","execution_count":166,"outputs":[{"output_type":"stream","text":"\n---- Fold 0 -----\n\n5955 5955\nTraining until validation scores don't improve for 200 rounds\n[100]\tvalid_0's rmse: 0.817926\n[200]\tvalid_0's rmse: 0.69717\n[300]\tvalid_0's rmse: 0.660329\n[400]\tvalid_0's rmse: 0.650743\n[500]\tvalid_0's rmse: 0.642567\n[600]\tvalid_0's rmse: 0.63678\n[700]\tvalid_0's rmse: 0.638605\n[800]\tvalid_0's rmse: 0.63863\nEarly stopping, best iteration is:\n[633]\tvalid_0's rmse: 0.635271\n\n Fold 0.6352712366996073\n\n->-> Fold ran for 0 minutes 5 seconds\n\n---- Fold 1 -----\n\n5955 5955\nTraining until validation scores don't improve for 200 rounds\n[100]\tvalid_0's rmse: 0.935327\n[200]\tvalid_0's rmse: 0.861931\n[300]\tvalid_0's rmse: 0.831636\n[400]\tvalid_0's rmse: 0.806751\n[500]\tvalid_0's rmse: 0.789842\n[600]\tvalid_0's rmse: 0.776548\n[700]\tvalid_0's rmse: 0.759778\n[800]\tvalid_0's rmse: 0.746812\n[900]\tvalid_0's rmse: 0.733454\n[1000]\tvalid_0's rmse: 0.724997\n[1100]\tvalid_0's rmse: 0.716986\nDid not meet early stopping. Best iteration is:\n[1100]\tvalid_0's rmse: 0.716986\n\n Fold 0.7169863117057657\n\n->-> Fold ran for 0 minutes 5 seconds\n\n---- Fold 2 -----\n\n5955 5955\nTraining until validation scores don't improve for 200 rounds\n[100]\tvalid_0's rmse: 0.947651\n[200]\tvalid_0's rmse: 0.883339\n[300]\tvalid_0's rmse: 0.869319\n[400]\tvalid_0's rmse: 0.862458\n[500]\tvalid_0's rmse: 0.861676\n[600]\tvalid_0's rmse: 0.857875\n[700]\tvalid_0's rmse: 0.85797\n[800]\tvalid_0's rmse: 0.857864\n[900]\tvalid_0's rmse: 0.856502\n[1000]\tvalid_0's rmse: 0.857913\n[1100]\tvalid_0's rmse: 0.855856\nDid not meet early stopping. Best iteration is:\n[1096]\tvalid_0's rmse: 0.855572\n\n Fold 0.855571918555813\n\n->-> Fold ran for 0 minutes 6 seconds\n\n---- Fold 3 -----\n\n5955 5955\nTraining until validation scores don't improve for 200 rounds\n[100]\tvalid_0's rmse: 0.81253\n[200]\tvalid_0's rmse: 0.754948\n[300]\tvalid_0's rmse: 0.727696\n[400]\tvalid_0's rmse: 0.714604\n[500]\tvalid_0's rmse: 0.706217\n[600]\tvalid_0's rmse: 0.703689\n[700]\tvalid_0's rmse: 0.697524\n[800]\tvalid_0's rmse: 0.693356\n[900]\tvalid_0's rmse: 0.691652\n[1000]\tvalid_0's rmse: 0.690283\n[1100]\tvalid_0's rmse: 0.686319\nDid not meet early stopping. Best iteration is:\n[1100]\tvalid_0's rmse: 0.686319\n\n Fold 0.6863190839265294\n\n->-> Fold ran for 0 minutes 5 seconds\n\n---- Fold 4 -----\n\n5955 5955\nTraining until validation scores don't improve for 200 rounds\n[100]\tvalid_0's rmse: 0.799747\n[200]\tvalid_0's rmse: 0.694987\n[300]\tvalid_0's rmse: 0.660081\n[400]\tvalid_0's rmse: 0.647972\n[500]\tvalid_0's rmse: 0.642659\n[600]\tvalid_0's rmse: 0.63827\n[700]\tvalid_0's rmse: 0.636796\n[800]\tvalid_0's rmse: 0.637437\n[900]\tvalid_0's rmse: 0.635167\n[1000]\tvalid_0's rmse: 0.634207\n[1100]\tvalid_0's rmse: 0.635973\nDid not meet early stopping. Best iteration is:\n[984]\tvalid_0's rmse: 0.633774\n\n Fold 0.633773572029877\n\n->-> Fold ran for 0 minutes 5 seconds\n\n---- Fold 5 -----\n\n5955 5955\nTraining until validation scores don't improve for 200 rounds\n[100]\tvalid_0's rmse: 0.81071\n[200]\tvalid_0's rmse: 0.718353\n[300]\tvalid_0's rmse: 0.691544\n[400]\tvalid_0's rmse: 0.677189\n[500]\tvalid_0's rmse: 0.669647\n[600]\tvalid_0's rmse: 0.663554\n[700]\tvalid_0's rmse: 0.660861\n[800]\tvalid_0's rmse: 0.654725\n[900]\tvalid_0's rmse: 0.652065\n[1000]\tvalid_0's rmse: 0.649716\n[1100]\tvalid_0's rmse: 0.647978\nDid not meet early stopping. Best iteration is:\n[1065]\tvalid_0's rmse: 0.64785\n\n Fold 0.6478499449919645\n\n->-> Fold ran for 0 minutes 5 seconds\n\n---- Fold 6 -----\n\n5955 5955\nTraining until validation scores don't improve for 200 rounds\n[100]\tvalid_0's rmse: 0.754191\n[200]\tvalid_0's rmse: 0.682762\n[300]\tvalid_0's rmse: 0.663843\n[400]\tvalid_0's rmse: 0.659936\n[500]\tvalid_0's rmse: 0.658527\n[600]\tvalid_0's rmse: 0.659603\n[700]\tvalid_0's rmse: 0.660382\nEarly stopping, best iteration is:\n[505]\tvalid_0's rmse: 0.6583\n\n Fold 0.6583004411824123\n\n->-> Fold ran for 0 minutes 5 seconds\n\n---- Fold 7 -----\n\n5955 5955\nTraining until validation scores don't improve for 200 rounds\n[100]\tvalid_0's rmse: 0.859988\n[200]\tvalid_0's rmse: 0.786138\n[300]\tvalid_0's rmse: 0.748473\n[400]\tvalid_0's rmse: 0.728662\n[500]\tvalid_0's rmse: 0.714894\n[600]\tvalid_0's rmse: 0.70305\n[700]\tvalid_0's rmse: 0.691309\n[800]\tvalid_0's rmse: 0.677363\n[900]\tvalid_0's rmse: 0.666735\n[1000]\tvalid_0's rmse: 0.657386\n[1100]\tvalid_0's rmse: 0.649933\nDid not meet early stopping. Best iteration is:\n[1100]\tvalid_0's rmse: 0.649933\n\n Fold 0.6499325979001547\n\n->-> Fold ran for 0 minutes 5 seconds\n\n---- Fold 8 -----\n\n5955 5955\nTraining until validation scores don't improve for 200 rounds\n[100]\tvalid_0's rmse: 0.840998\n[200]\tvalid_0's rmse: 0.773619\n[300]\tvalid_0's rmse: 0.736644\n[400]\tvalid_0's rmse: 0.714247\n[500]\tvalid_0's rmse: 0.700505\n[600]\tvalid_0's rmse: 0.690478\n[700]\tvalid_0's rmse: 0.675868\n[800]\tvalid_0's rmse: 0.664614\n[900]\tvalid_0's rmse: 0.658687\n[1000]\tvalid_0's rmse: 0.649321\n[1100]\tvalid_0's rmse: 0.646477\nDid not meet early stopping. Best iteration is:\n[1094]\tvalid_0's rmse: 0.646401\n\n Fold 0.6464008632715523\n\n->-> Fold ran for 0 minutes 5 seconds\n\n---- Fold 9 -----\n\n5955 5955\nTraining until validation scores don't improve for 200 rounds\n[100]\tvalid_0's rmse: 0.944127\n[200]\tvalid_0's rmse: 0.907382\n[300]\tvalid_0's rmse: 0.897198\n[400]\tvalid_0's rmse: 0.8881\n[500]\tvalid_0's rmse: 0.882894\n[600]\tvalid_0's rmse: 0.879159\n[700]\tvalid_0's rmse: 0.875868\n[800]\tvalid_0's rmse: 0.870707\n[900]\tvalid_0's rmse: 0.863359\n[1000]\tvalid_0's rmse: 0.860513\n[1100]\tvalid_0's rmse: 0.861703\nDid not meet early stopping. Best iteration is:\n[994]\tvalid_0's rmse: 0.860339\n\n Fold 0.860339114162237\n\n->-> Fold ran for 0 minutes 5 seconds\n\n---- Fold 10 -----\n\n5955 5955\nTraining until validation scores don't improve for 200 rounds\n[100]\tvalid_0's rmse: 0.79954\n[200]\tvalid_0's rmse: 0.724209\n[300]\tvalid_0's rmse: 0.699835\n[400]\tvalid_0's rmse: 0.680899\n[500]\tvalid_0's rmse: 0.67152\n[600]\tvalid_0's rmse: 0.666225\n[700]\tvalid_0's rmse: 0.666912\n[800]\tvalid_0's rmse: 0.668128\nEarly stopping, best iteration is:\n[613]\tvalid_0's rmse: 0.665306\n\n Fold 0.6653061099641299\n\n->-> Fold ran for 0 minutes 5 seconds\n\n---- Fold 11 -----\n\n5955 5955\nTraining until validation scores don't improve for 200 rounds\n[100]\tvalid_0's rmse: 0.891863\n[200]\tvalid_0's rmse: 0.804348\n[300]\tvalid_0's rmse: 0.763118\n[400]\tvalid_0's rmse: 0.74541\n[500]\tvalid_0's rmse: 0.732488\n[600]\tvalid_0's rmse: 0.718844\n[700]\tvalid_0's rmse: 0.708745\n[800]\tvalid_0's rmse: 0.6981\n[900]\tvalid_0's rmse: 0.688834\n[1000]\tvalid_0's rmse: 0.677932\n[1100]\tvalid_0's rmse: 0.67169\nDid not meet early stopping. Best iteration is:\n[1098]\tvalid_0's rmse: 0.671618\n\n Fold 0.6716184489480853\n\n->-> Fold ran for 0 minutes 5 seconds\n\n---- Fold 12 -----\n\n5955 5955\nTraining until validation scores don't improve for 200 rounds\n[100]\tvalid_0's rmse: 0.780448\n[200]\tvalid_0's rmse: 0.720765\n[300]\tvalid_0's rmse: 0.690742\n[400]\tvalid_0's rmse: 0.67568\n[500]\tvalid_0's rmse: 0.670444\n[600]\tvalid_0's rmse: 0.66406\n[700]\tvalid_0's rmse: 0.659023\n[800]\tvalid_0's rmse: 0.65516\n[900]\tvalid_0's rmse: 0.65001\n[1000]\tvalid_0's rmse: 0.64494\n[1100]\tvalid_0's rmse: 0.640766\nDid not meet early stopping. Best iteration is:\n[1100]\tvalid_0's rmse: 0.640766\n\n Fold 0.6407656216681217\n\n->-> Fold ran for 0 minutes 5 seconds\n\n---- Fold 13 -----\n\n5955 5955\nTraining until validation scores don't improve for 200 rounds\n[100]\tvalid_0's rmse: 0.865581\n[200]\tvalid_0's rmse: 0.798626\n[300]\tvalid_0's rmse: 0.764795\n[400]\tvalid_0's rmse: 0.746184\n[500]\tvalid_0's rmse: 0.735041\n[600]\tvalid_0's rmse: 0.723692\n[700]\tvalid_0's rmse: 0.713139\n[800]\tvalid_0's rmse: 0.711661\n[900]\tvalid_0's rmse: 0.711362\n[1000]\tvalid_0's rmse: 0.706445\n[1100]\tvalid_0's rmse: 0.704092\nDid not meet early stopping. Best iteration is:\n[1092]\tvalid_0's rmse: 0.703994\n\n Fold 0.7039942989769584\n\n->-> Fold ran for 0 minutes 5 seconds\n\n---- Fold 14 -----\n\n5955 5955\nTraining until validation scores don't improve for 200 rounds\n[100]\tvalid_0's rmse: 0.832418\n[200]\tvalid_0's rmse: 0.743312\n[300]\tvalid_0's rmse: 0.714811\n[400]\tvalid_0's rmse: 0.705804\n[500]\tvalid_0's rmse: 0.701697\n[600]\tvalid_0's rmse: 0.696321\n[700]\tvalid_0's rmse: 0.694983\n[800]\tvalid_0's rmse: 0.693905\n[900]\tvalid_0's rmse: 0.696436\nEarly stopping, best iteration is:\n[761]\tvalid_0's rmse: 0.693606\n\n Fold 0.6936064823417005\n\n->-> Fold ran for 0 minutes 5 seconds\n\n---- Fold 15 -----\n\n5955 5955\n","name":"stdout"},{"output_type":"stream","text":"Training until validation scores don't improve for 200 rounds\n[100]\tvalid_0's rmse: 0.93083\n[200]\tvalid_0's rmse: 0.856927\n[300]\tvalid_0's rmse: 0.820039\n[400]\tvalid_0's rmse: 0.794883\n[500]\tvalid_0's rmse: 0.77722\n[600]\tvalid_0's rmse: 0.764827\n[700]\tvalid_0's rmse: 0.752347\n[800]\tvalid_0's rmse: 0.743308\n[900]\tvalid_0's rmse: 0.738277\n[1000]\tvalid_0's rmse: 0.735426\n[1100]\tvalid_0's rmse: 0.729049\nDid not meet early stopping. Best iteration is:\n[1098]\tvalid_0's rmse: 0.728983\n\n Fold 0.728982818383847\n\n->-> Fold ran for 0 minutes 5 seconds\n\n---- Fold 16 -----\n\n5955 5955\nTraining until validation scores don't improve for 200 rounds\n[100]\tvalid_0's rmse: 0.804495\n[200]\tvalid_0's rmse: 0.748252\n[300]\tvalid_0's rmse: 0.730328\n[400]\tvalid_0's rmse: 0.721479\n[500]\tvalid_0's rmse: 0.720015\n[600]\tvalid_0's rmse: 0.720873\nEarly stopping, best iteration is:\n[457]\tvalid_0's rmse: 0.719185\n\n Fold 0.7191851050497591\n\n->-> Fold ran for 0 minutes 5 seconds\n\n---- Fold 17 -----\n\n5955 5955\nTraining until validation scores don't improve for 200 rounds\n[100]\tvalid_0's rmse: 0.888594\n[200]\tvalid_0's rmse: 0.810773\n[300]\tvalid_0's rmse: 0.774932\n[400]\tvalid_0's rmse: 0.762821\n[500]\tvalid_0's rmse: 0.750186\n[600]\tvalid_0's rmse: 0.744255\n[700]\tvalid_0's rmse: 0.739627\n[800]\tvalid_0's rmse: 0.731738\n[900]\tvalid_0's rmse: 0.731067\n[1000]\tvalid_0's rmse: 0.729404\n[1100]\tvalid_0's rmse: 0.730591\nDid not meet early stopping. Best iteration is:\n[1001]\tvalid_0's rmse: 0.729292\n\n Fold 0.7292918547606672\n\n->-> Fold ran for 0 minutes 5 seconds\n\n---- Fold 18 -----\n\n5955 5955\nTraining until validation scores don't improve for 200 rounds\n[100]\tvalid_0's rmse: 0.868092\n[200]\tvalid_0's rmse: 0.791068\n[300]\tvalid_0's rmse: 0.7668\n[400]\tvalid_0's rmse: 0.759274\n[500]\tvalid_0's rmse: 0.753363\n[600]\tvalid_0's rmse: 0.7569\n[700]\tvalid_0's rmse: 0.760977\nEarly stopping, best iteration is:\n[506]\tvalid_0's rmse: 0.753191\n\n Fold 0.7531910732349545\n\n->-> Fold ran for 0 minutes 5 seconds\n\n---- Fold 19 -----\n\n5955 5955\nTraining until validation scores don't improve for 200 rounds\n[100]\tvalid_0's rmse: 0.92761\n[200]\tvalid_0's rmse: 0.822855\n[300]\tvalid_0's rmse: 0.763584\n[400]\tvalid_0's rmse: 0.737594\n[500]\tvalid_0's rmse: 0.719298\n[600]\tvalid_0's rmse: 0.704458\n[700]\tvalid_0's rmse: 0.69164\n[800]\tvalid_0's rmse: 0.680653\n[900]\tvalid_0's rmse: 0.669856\n[1000]\tvalid_0's rmse: 0.662782\n[1100]\tvalid_0's rmse: 0.65485\nDid not meet early stopping. Best iteration is:\n[1100]\tvalid_0's rmse: 0.65485\n\n Fold 0.6548498492982509\n\n->-> Fold ran for 0 minutes 5 seconds\n\nOOF val score: 0.7004693645723346\n\n->-> Total training time: 1 minutes 50 seconds\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"vp4, tp4 = oofs, test_preds","execution_count":167,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"##vp0*0.1 + vp1*0.2 + vp2*0.7  0.62\n\ntest_preds =  tp0*0.1  + tp1*0.4 + tp2*0.6","execution_count":193,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(f'\\nOOF val score: {rmse(np.log(target), np.log(oofs))}')","execution_count":194,"outputs":[{"output_type":"stream","text":"\nOOF val score: 0.7004693645723346\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nprint(f'\\nOOF val score: {rmse(np.log(target), np.log( vp1*0.2 + vp2*0.7 + vp3*0.1 ))}')","execution_count":195,"outputs":[{"output_type":"stream","text":"\nOOF val score: 0.6291850635550152\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub = pd.DataFrame({'Selling_Price': test_preds})\nsub['Selling_Price'] = np.clip(sub['Selling_Price'], target.min(), target.max())\nsub['Selling_Price'].describe()","execution_count":196,"outputs":[{"output_type":"execute_result","execution_count":196,"data":{"text/plain":"count     1051.000000\nmean      2014.203959\nstd       5865.736234\nmin        176.013813\n25%        491.016208\n50%        686.625497\n75%        950.073945\nmax      52970.848329\nName: Selling_Price, dtype: float64"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nsub.head(10)","execution_count":197,"outputs":[{"output_type":"execute_result","execution_count":197,"data":{"text/plain":"   Selling_Price\n0    2730.792557\n1     504.778122\n2     832.701076\n3     385.966062\n4     791.196730\n5     785.559543\n6     406.762054\n7   11670.879725\n8   29594.203518\n9     353.101631","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Selling_Price</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2730.792557</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>504.778122</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>832.701076</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>385.966062</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>791.196730</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>785.559543</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>406.762054</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>11670.879725</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>29594.203518</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>353.101631</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"np.savetxt(\"submit1871.csv\", sub, delimiter=\",\")","execution_count":198,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"filepath = 'submit.xlsx'\n\ndf.to_excel(sub, index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}